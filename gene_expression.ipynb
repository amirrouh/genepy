{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenePy\n",
    "\n",
    "## This is a python module to analysis gene expression profile from the ncbi GEO database.\n",
    "\n",
    "Goal is to build a flexible tookbox for gene expression profile analysis using machine learning. Although there are similar toolboxes, GenePy will be more focused on flexibility and being user-friendly. So the researches from all over the world can openly access to this tool and use different machine learning models for analysis.\n",
    "\n",
    "## Parser\n",
    "\n",
    "    \n",
    "    This module downloads gene expression profile from NCBI GEO FTP website and parses it\n",
    "    Parameters\n",
    "    ----------\n",
    "    link  : str\n",
    "    This is the link to GEO soft_full.gz file on NCBI website\n",
    "    data_dim  : int\n",
    "    This gets number of genes needed to be considered ( data_dim = 10; only first 10 genes from the\n",
    "    top of the input file will be considered in parsing data and data_dim = None means all the data)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataset : numpy array\n",
    "    dataset is a numpy array. Each row represents one cell gene expression data, the i_th column\n",
    "    from the left shows the i_th gene expression values from the top in row input data table and\n",
    "    the last column on the right shows the subset description type 0 being the first one showing \n",
    "    in the input file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(link, data_dim):\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    from matplotlib.pyplot import plot as plt\n",
    "    import os\n",
    "    \n",
    "    file_name = link.split('/')[-1]\n",
    "    dir_root = os.listdir()\n",
    "\n",
    "    if 'temp' not in dir_root: \n",
    "        os.mkdir('temp')\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "    dir_temp = os.listdir('temp/')\n",
    "\n",
    "    # If the input file does not exist then it will download the file, otherfiles, \n",
    "    # the code will use the existing file\n",
    "    if file_name not in dir_temp: \n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(link, 'temp/' + file_name)[0]\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Data input dimension to simplify is defined (None => imports all the genes \n",
    "    # unless number of genes are declared)\n",
    "\n",
    "    with gzip.open('temp/' + file_name, 'rt') as f:\n",
    "        #    sd: subset description\n",
    "        #    si: subset id\n",
    "        #    ge: gene expression\n",
    "        sd, si, ge = [], [], []\n",
    "        \n",
    "        #    Obtain subset description\n",
    "        for line in f:\n",
    "            if \"!subset_description\" in line:\n",
    "                sd.append(line.split('=')[1].strip())\n",
    "                \n",
    "            elif \"!subset_sample_id\" in line:\n",
    "                si.append(line.split('=')[1].strip().split(','))\n",
    "                \n",
    "            elif \"!dataset_table_begin\" in line:\n",
    "                break\n",
    "            \n",
    "        subset_number = sum(len(sd) for sd in si)\n",
    "        #  Read the gene info table\n",
    "\n",
    "        for line in f:\n",
    "            if \"!dataset_table_begin\" in line:\n",
    "                break            \n",
    "    \n",
    "            elif \"!dataset_table_end\" in line:\n",
    "                break\n",
    "    \n",
    "            ge.append(line.split()[:2 + subset_number])\n",
    "    \n",
    "    ge = pd.DataFrame(ge)\n",
    "    new_header = ge.iloc[0]\n",
    "    ge.columns = new_header\n",
    "    ge = ge[1:]\n",
    "\n",
    "\n",
    "    '''\n",
    "    #   Here, we create a temporary directory to store needed files\n",
    "    ge.to_pickle('temp/ge')\n",
    "    pickle.dump(sd , open( 'temp/sd', 'wb' ))\n",
    "    pickle.dump(si , open( 'temp/si', 'wb' ))\n",
    "    '''\n",
    "\n",
    "\n",
    "    ge_array = np.array(ge)\n",
    "    d = ge_array[:, 2:].astype(float)\n",
    "\n",
    "    # Convert numpy array to training format for SVM solver\n",
    "    data = []\n",
    "    for i in range(len(d[0,:])):\n",
    "        data.append(d[:data_dim,i])\n",
    "    data = np.array(data)\n",
    "\n",
    "    #   Assign numbers to subset types and make a target vector for classification\n",
    "    labels = []\n",
    "    for i in range(0, len(sd)):\n",
    "        labels.append(len(si[i]) * [i])\n",
    "    \n",
    "    #   Merge the target groups (each type is a list in python, \n",
    "    #   this part merges the parts to have unit target vector)\n",
    "    label_tmp = []\n",
    "    for j in range(len(labels)):\n",
    "        label_tmp += labels[j]\n",
    "    labels = np.array(label_tmp)\n",
    "\n",
    "    # dimension of input gene expression\n",
    "    label_dimension = len(ge_array[0,2:])\n",
    "    labels = labels.reshape((label_dimension,1))\n",
    "\n",
    "\n",
    "    #   This line joins the data and labels as a new 2D array\n",
    "    dataset = np.concatenate((data, labels), axis=1)\n",
    "\n",
    "    #   This part randomly shuffles the data to be ready for training and testing purposes\n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    # This file will be saved into temp folder in case of any need for review\n",
    "    np.savetxt('temp/dataset.csv', dataset, fmt='%.3f', delimiter=',', newline='\\n', header='')\n",
    "\n",
    "    # This binary file will be save in the temp folder for faster load in other modules\n",
    "    np.save('temp/dataset_binary', dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "    This module has all the parameters and values\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    parameters : dict\n",
    "        Return a dictionary of all the parameters and the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def database():\n",
    "    #   Server parameters\n",
    "    parameters = {'directory_1': 'local_directory',\n",
    "                  'directory_2': 'directory_on_server',\n",
    "                  'key_address': 'full_address_to_the_ssh_key_file',\n",
    "                  'user': 'username', 'server': 'server address',\n",
    "\n",
    "                  #   Parsing parameters\n",
    "                  'link': 'ftp://ftp.ncbi.nlm.nih.gov/geo/datasets/GDS1nnn/GDS1615/soft/GDS1615_full.soft.gz',\n",
    "                  'input_dim': 500,\\\n",
    "\n",
    "                  #   Autoencoder parameters\n",
    "                  'epoch': 50, 'batch': 200, 'latent': 30, 'encoder_o': 100,\n",
    "                  'encoder_i': 50, 'decoder_i': 50, 'decoder_o': 100, 'train_percent': 75,\n",
    "                  'lam': 0.0001, 'loss_plot': False, 'norm_order': 10,\\\n",
    "\n",
    "                  #   SVM parameters\n",
    "                  'train_percent': 75, 'gamma': 0.0001, 'c': 1000000}\n",
    "\n",
    "    keys = list(parameters.keys())\n",
    "    values = list(parameters.values())\n",
    "\n",
    "    #   converts the long dictionary to list of small dictionaries consist of a variable and values\n",
    "    packed = []\n",
    "    for i in range(len(keys)):\n",
    "        key = [keys[i]]\n",
    "        value = [values[i]]\n",
    "        packed.append(dict(zip(key, value)))\n",
    "\n",
    "    return parameters, packed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This following function changes the parameter format and prepares to run the model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter: str\n",
    "        Parameters name which is to be changed\n",
    "    value: NA\n",
    "        Value of the parameter which is changing\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    parameters : dict\n",
    "        Return a dictionary of all the parameters and the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametrize(parameter, value):\n",
    "\n",
    "    #   Read the database as a big dictionary and change the values and retuns big\n",
    "    #   dictionary and list of small dictionatries\n",
    "    parameters, _ = database()\n",
    "\n",
    "    parameters[parameter] = value\n",
    "\n",
    "    keys = list(parameters.keys())\n",
    "    values = list(parameters.values())\n",
    "\n",
    "    #   converts the long dictionary to list of small dictionaries consist of a variable and values\n",
    "    packed = []\n",
    "    for i in range(len(keys)):\n",
    "        key = [keys[i]]\n",
    "        value = [values[i]]\n",
    "        packed.append(dict(zip(key, value)))\n",
    "\n",
    "    return parameters, packed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core\n",
    "This module handles more general functions such as logging the processes and cleanup previous files from last run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def log(entry):\n",
    "    '''\n",
    "    This function logs epecific event to a file 'log.txt'\n",
    "\n",
    "    Parameters\n",
    "    -----\n",
    "\n",
    "    Returns\n",
    "    -----\n",
    "\n",
    "    '''\n",
    "    with open('temp/log.txt', 'a') as file:\n",
    "        file.writelines(entry + '\\n')\n",
    "\n",
    "\n",
    "def clean():\n",
    "    '''\n",
    "    This function cleans the temp folder from last run\n",
    "\n",
    "    Parameters\n",
    "    -----\n",
    "\n",
    "    Returns\n",
    "    -----\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        shutil.rmtree('temp')\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoder (Data compression)\n",
    "\n",
    "    This module is autoencoder neural network which gets input data and\n",
    "    reduces the dimension and returns similar data to the input. Data \n",
    "    compression is useful for future data manipulation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch  : int\n",
    "        Epoch gets the epoch number of the neural network passed through\n",
    "        the neural network in each iteration\n",
    "    batch  : int\n",
    "        Batch number of the neural network determines how many times all \n",
    "        the data will be passed through the neural network\n",
    "    latent : int\n",
    "        Latent vector dimension shows the size of buttleneck (compressed data)\n",
    "    encoder_o : int\n",
    "        Size of outer encoder hidden layer of the neural network close to the \n",
    "        input\n",
    "    encoder_i : int\n",
    "        size of inner encoder hidden layer of the neural network close to the \n",
    "        buttleneck\n",
    "    decore_i : int\n",
    "        size of inner decoder hidden layer of the neural network close to the \n",
    "        buttleneck\n",
    "    decore_o : int\n",
    "        size of outer decoder hidden layer of the neural network close to the \n",
    "        output\n",
    "    train_percent : float\n",
    "        (The value will be between 0 and 100) shows what fraction of the dataset\n",
    "        will be used for training and the rest for testing\n",
    "    lam : float\n",
    "        The coefficient of regularization for the autoencoder model\n",
    "    norm_order: int \n",
    "        keras data normalization parameter\n",
    "    loss_plot : Boolean\n",
    "        If True plots the loss function and if False, does not plot that\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    input : list\n",
    "        gives all the inputs used for training\n",
    "    latent vector : list\n",
    "        Latent vector, the compressed representation of the input\n",
    "    reconstructed: list\n",
    "        Gives the reconstructed data from the input  \n",
    "    cell_types: list\n",
    "        Gives a list of integers represent cell types for the given input data\n",
    "    auto_runtime : float\n",
    "        Training runtime in seconds\n",
    "    auto_err: float\n",
    "        The autoencoder average error (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder (epoch, batch, latent, encoder_o, encoder_i, \\\n",
    "    decoder_i, decoder_o, train_percent, lam, norm_order, loss_plot):\n",
    "\n",
    "    #   Import required libraries\n",
    "    from keras import callbacks\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.models import Model\n",
    "    from keras.utils import normalize\n",
    "    from keras import regularizers\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib.pyplot import draw, show\n",
    "    import pickle\n",
    "    import time\n",
    "\n",
    "    #   starting time is measured to compare performance\"\"\"\n",
    "    time_start = time.time()\n",
    "\n",
    "    #   Importing the database parsed from the input file\n",
    "    dataset = np.load('temp/dataset_binary.npy')\n",
    "\n",
    "    #   PErforme log transform and normalization before analysis\n",
    "    input_data =np.log(dataset[:,:-1]) / np.log(2)\n",
    "    input_data = normalize(input_data, axis=0, order=norm_order)\n",
    "    input_size = len(input_data[0, :])\n",
    "\n",
    "    #   Split cell types list from the raw data and keep it\n",
    "    labels = dataset[:,-1]\n",
    "\n",
    "    #   Split training and testing data from the input dataset\n",
    "    percent_training = int(len(input_data[:, 0]) * (train_percent/100))\n",
    "    X_train = input_data[:percent_training,:input_size]\n",
    "    L_train = dataset[:percent_training, -1]\n",
    "    X_test = input_data [percent_training:,:input_size]\n",
    "    L_test = dataset[percent_training:, -1]\n",
    "\n",
    "    #   Define network parameters\n",
    "    epoch_size = epoch\n",
    "    batch_size = batch\n",
    "    latent_dim = latent\n",
    "\n",
    "    #   Lambda coefficnet of l2 regulizor of the keras\n",
    "    lam = lam\n",
    "\n",
    "    ### Building the neural network layers\n",
    "    encoder_o = encoder_o\n",
    "    encoder_i = encoder_i\n",
    "    decoder_i = decoder_i\n",
    "    decoder_o = decoder_o\n",
    "\n",
    "    #   building the input layer\n",
    "    input_gene_expression = Input(shape=(input_size,))\n",
    "\n",
    "    \"\"\"#### Encoder layer\n",
    "    The encoder layer will connet input layer to the latent vector.\n",
    "    In order to avoid ovefitting, l2 regularization methos is used which \n",
    "    changes loss function for larger weights.\n",
    "    \"\"\"\n",
    "    encoded = Dense(encoder_o, kernel_regularizer=regularizers.l2(lam), \\\n",
    "        activation=tf.nn.relu)(input_gene_expression)\n",
    "    encoded = Dense(encoder_i, kernel_regularizer=regularizers.l2(lam), \\\n",
    "        activation=tf.nn.relu)(encoded)\n",
    "    encoded = Dense(latent_dim, kernel_regularizer=regularizers.l2(lam), \\\n",
    "        activation=tf.nn.relu)(encoded)\n",
    "\n",
    "    \"\"\"#### Decoder layer\n",
    "    Decoder layer is defined same as encoder layer but, it connects latent space\n",
    "     to the output layer.\n",
    "    \"\"\"\n",
    "    decoded = Dense(decoder_i, kernel_regularizer=regularizers.l2(lam), \\\n",
    "        activation =tf.nn.relu)(encoded)\n",
    "    decoded = Dense(decoder_o, kernel_regularizer=regularizers.l2(lam), \\\n",
    "        activation =tf.nn.relu)(decoded)\n",
    "    decoded = Dense(input_size, kernel_regularizer=regularizers.l2(lam), \\\n",
    "        activation =tf.nn.sigmoid)(decoded)\n",
    "\n",
    "    \"\"\"\n",
    "    The autoencoder model is created mapping input data to reconstructed data \n",
    "    similar to the input.\n",
    "    \"\"\"\n",
    "    autoencoder = Model(input_gene_expression, decoded)\n",
    "\n",
    "    \"\"\"\n",
    "    Encoder model is created to show the latent vectors\n",
    "    \"\"\"\n",
    "    encoder = Model(input_gene_expression, encoded)\n",
    "    \n",
    "    \"\"\"\n",
    "    Loss function of variational autoencoder is defined as the distance between\n",
    "    input and output using mean squared error (MSE). The optimizer \"adam\" is \n",
    "    then used to minimize the MSE function\n",
    "    \"\"\"\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=\\\n",
    "        ['accuracy'])\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Training the autoencoder model: Network dimensions, batch and epoch sizes \n",
    "    and training and testing datasets are used to train the model\n",
    "    \"\"\"\n",
    "\n",
    "    #   This section defins the plot and callback functions to track training\n",
    "    class PlotLosses(callbacks.Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.i = 0\n",
    "            self.x = []\n",
    "            self.losses = []\n",
    "            self.val_losses = []\n",
    "            \n",
    "            self.fig = plt.figure()\n",
    "            \n",
    "            self.logs = []\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            self.logs.append(logs)\n",
    "            self.x.append(self.i)\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            self.i += 1\n",
    "\n",
    "            if loss_plot:\n",
    "                plt.plot(self.x, self.losses, label=\"Training loss\", c = 'b', \\\n",
    "                    linestyle = '-')\n",
    "                plt.plot(self.x, self.val_losses, label=\"Validation loss\",\\\n",
    "                     c = 'b', linestyle = '-.')\n",
    "                plt.pause(0.01)\n",
    "                plt.title('Training loss: ---, Validation loss: -.-.')\n",
    "                plt.xlabel('Epoch number')\n",
    "                plt.ylabel('MSE value')\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "    time_start = time.time()\n",
    "    autoencoder.fit(X_train, X_train, epochs=epoch_size, batch_size=batch_size,\\\n",
    "                    shuffle=True, callbacks=[PlotLosses()], validation_data=\\\n",
    "                        (X_test, X_test), verbose=1)\n",
    "\n",
    "\n",
    "    #   Build reconstructed testing layer to measure the autoencoder's error\n",
    "    reconstructed_test = autoencoder.predict(X_test)\n",
    " \n",
    "    #   Autoencoder training runtime is calculated\n",
    "    time_end = time.time()\n",
    "    auto_runtime = time_end - time_start\n",
    "\n",
    "\n",
    "    #   Autoencoder error is defined\n",
    "    diff = abs(X_test - reconstructed_test)\n",
    "    diff_mean = np.mean(diff)\n",
    "    mean = np.mean(abs(X_test))\n",
    "    auto_err = diff_mean / mean\n",
    "\n",
    "    #   show() function, keeps the plot open until the computation is finished\n",
    "    if loss_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #   Build latent and reconstruction tensors\n",
    "    latent = encoder.predict(input_data)\n",
    "    reconstructed = autoencoder.predict(input_data)\n",
    "\n",
    "    #   exporting latent file and labels for classifier\n",
    "    pickle.dump(latent, open('temp/latent', 'wb'))\n",
    "    pickle.dump(labels, open('temp/labels', 'wb'))\n",
    "    plt.close()\n",
    "    \n",
    "    return input_data, latent, reconstructed, labels, auto_runtime, auto_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (Classifier)\n",
    "    This module uses support vector machine (SVM) to classify the cell types \n",
    "    based on their compressed gene expression profile (latent vectors)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma  : float\n",
    "        C-support nonlinear SVM Parameter (Gamma)\n",
    "    c : float\n",
    "        C-support nonlinear SVM Parameter (C)\n",
    "    percent : float\n",
    "        show what percentage is used for training (between 0 and 100)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    label_predicted: list\n",
    "        List of label predictions\n",
    "    svm_runtime : loat\n",
    "        SVM runtime in seconds\n",
    "    svm_err : float\n",
    "        SVM average error (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify (gamma, c, train_percent):\n",
    "    #   Import required libraries\n",
    "    from sklearn import svm\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import time\n",
    "\n",
    "\n",
    "    #   Start time to measure SVM runtime\n",
    "    time_start = time.time()\n",
    "\n",
    "    #   Import latent data and labels (created by the autoencoder)\n",
    "    latent = pickle.load(open('temp/latent', 'rb'))\n",
    "    labels = pickle.load(open('temp/labels', 'rb'))\n",
    "\n",
    "    #   Prepare testing and training datasets\n",
    "    input_size = len(latent[0, :])\n",
    "    percent_training = int(len(latent[:, 0]) * (train_percent/100))\n",
    "    latent_train = latent[:percent_training,:input_size]\n",
    "    label_train = labels[:percent_training]\n",
    "    latent_test = latent[percent_training:,:input_size]\n",
    "    label_test = labels[percent_training:]\n",
    "\n",
    "    #   SVM training function\n",
    "    def cell_classifier(input):\n",
    "        model = svm.SVC(gamma=gamma, C=c)\n",
    "        model.fit(latent_train, label_train)\n",
    "        output = model.predict(input)\n",
    "        return output\n",
    "\n",
    "    #   Make predictions based on the testing latent vectors\n",
    "    label_predicted = cell_classifier(latent_test)\n",
    "\n",
    "    #   Classification error calculation\n",
    "    missclassified = np.count_nonzero(label_test - label_predicted)\n",
    "    svm_err = missclassified / len(label_test)\n",
    "\n",
    "\n",
    "    #   SVM Runtime is measured\n",
    "    time_end = time.time()\n",
    "    svm_runtime = time_end - time_start\n",
    "\n",
    "    return label_predicted, svm_runtime, svm_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity\n",
    "\n",
    "This module includes sensitivity analyis function to measure autoencoder and SVM\n",
    "accuracy and performance and hanges a parameters by the values provided and returns \n",
    "autoencoder and SVM runtime and errors.\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    test_samples: list\n",
    "        list of dictionaries for each parameter to test\n",
    "        (i.e. [{'epoch':range(10,30,10)}, {'batch':range(500,700,100)}])\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    [auto_runtime, auto_err, svm_runtime, svm_err]\n",
    "    \n",
    "    where:\n",
    "\n",
    "    auto_runtime : float\n",
    "        Autoencoder runtime in seconds\n",
    "    auto_err : float\n",
    "        Autoencoder average error in percentage\n",
    "    svm_runtime : float\n",
    "        SVM runtime in second\n",
    "    svm_err : float\n",
    "        SVM average error in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_samples):\n",
    "\n",
    "    #   Import required libraries\n",
    "    import numpy as np\n",
    "\n",
    "    for test in test_samples:\n",
    "        parameter, values = list(test.keys())[0], list(test.values())[0]\n",
    "        #   Run the functions to assess performance, the inputs are passed in shape of dictionary\n",
    "        def whole_model(**kwargs):\n",
    "            read(kwargs['link'], kwargs['input_dim'])\n",
    "            _, _, _, _, auto_runtime, auto_err = \\\n",
    "                autoencoder(kwargs['epoch'], kwargs['batch'], kwargs['latent'],\n",
    "                            kwargs['encoder_o'], kwargs['encoder_i'], kwargs['decoder_i'], \n",
    "                            kwargs['decoder_o'], kwargs['train_percent'], kwargs['lam'], \n",
    "                            kwargs['norm_order'], kwargs['loss_plot'])\n",
    "            _, svm_runtime, svm_err = classify(kwargs['gamma'], kwargs['c'], kwargs['train_percent'])\n",
    "            return auto_runtime, auto_err, svm_runtime, svm_err\n",
    "\n",
    "\n",
    "        auto_runtime, auto_err, svm_runtime, svm_err = [], [], [], []\n",
    "\n",
    "        for v in values:\n",
    "            parameters, _ = parametrize(parameter, v)\n",
    "            #   Here **, unzips parameters dictionary to argument before passing to the function\n",
    "            a_runtime, a_err, s_runtime, s_err = whole_model(**parameters)\n",
    "            auto_runtime.append(a_runtime)\n",
    "            auto_err.append(a_err)\n",
    "            svm_runtime.append(s_runtime)\n",
    "            svm_err.append(s_err)\n",
    "            \n",
    "    return auto_runtime, auto_err, svm_runtime, svm_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "In this section, we can plot some of the analysis done by the autoencoder-SVM model on gene profile data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0640 - acc: 0.0000e+00 - val_loss: 0.0632 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 113us/step - loss: 0.0632 - acc: 0.0000e+00 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0623 - acc: 0.0000e+00 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0613 - acc: 0.0000e+00 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0602 - acc: 0.0000e+00 - val_loss: 0.0592 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0591 - acc: 0.0000e+00 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0580 - acc: 0.0000e+00 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0568 - acc: 0.0000e+00 - val_loss: 0.0556 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0555 - acc: 0.0000e+00 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0542 - acc: 0.0000e+00 - val_loss: 0.0529 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0529 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0514 - acc: 0.0000e+00 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0499 - acc: 0.0000e+00 - val_loss: 0.0484 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0483 - acc: 0.0000e+00 - val_loss: 0.0468 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.0453 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0452 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0438 - acc: 0.0000e+00 - val_loss: 0.0425 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0386 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0224 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0219 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0211 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0647 - acc: 0.0000e+00 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 160us/step - loss: 0.0639 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0629 - acc: 0.0000e+00 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0619 - acc: 0.0000e+00 - val_loss: 0.0608 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0607 - acc: 0.0000e+00 - val_loss: 0.0595 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0594 - acc: 0.0000e+00 - val_loss: 0.0581 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0580 - acc: 0.0000e+00 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0565 - acc: 0.0000e+00 - val_loss: 0.0551 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0550 - acc: 0.0000e+00 - val_loss: 0.0535 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0534 - acc: 0.0000e+00 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0518 - acc: 0.0000e+00 - val_loss: 0.0503 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0502 - acc: 0.0000e+00 - val_loss: 0.0487 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0486 - acc: 0.0000e+00 - val_loss: 0.0472 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.0458 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0457 - acc: 0.0000e+00 - val_loss: 0.0444 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0443 - acc: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0429 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0406 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0234 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0225 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0216 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0658 - acc: 0.0000e+00 - val_loss: 0.0644 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 201us/step - loss: 0.0646 - acc: 0.0000e+00 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0636 - acc: 0.0000e+00 - val_loss: 0.0624 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0626 - acc: 0.0000e+00 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0615 - acc: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0602 - acc: 0.0000e+00 - val_loss: 0.0586 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0588 - acc: 0.0000e+00 - val_loss: 0.0571 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0573 - acc: 0.0000e+00 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0557 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0541 - acc: 0.0000e+00 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0525 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0510 - acc: 0.0000e+00 - val_loss: 0.0493 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0495 - acc: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0481 - acc: 0.0000e+00 - val_loss: 0.0464 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0466 - acc: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0453 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0440 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0407 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0225 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0666 - acc: 0.0000e+00 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 124us/step - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.0644 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0646 - acc: 0.0000e+00 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0636 - acc: 0.0000e+00 - val_loss: 0.0624 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0625 - acc: 0.0000e+00 - val_loss: 0.0612 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0614 - acc: 0.0000e+00 - val_loss: 0.0599 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0601 - acc: 0.0000e+00 - val_loss: 0.0586 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0588 - acc: 0.0000e+00 - val_loss: 0.0572 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0573 - acc: 0.0000e+00 - val_loss: 0.0557 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0559 - acc: 0.0000e+00 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0544 - acc: 0.0000e+00 - val_loss: 0.0528 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0529 - acc: 0.0000e+00 - val_loss: 0.0513 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0514 - acc: 0.0000e+00 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0500 - acc: 0.0000e+00 - val_loss: 0.0485 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0486 - acc: 0.0000e+00 - val_loss: 0.0471 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0472 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0458 - acc: 0.0000e+00 - val_loss: 0.0444 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0433 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0410 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0410 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0381 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0226 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 10ms/step - loss: 0.0660 - acc: 0.0000e+00 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 163us/step - loss: 0.0651 - acc: 0.0000e+00 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0642 - acc: 0.0000e+00 - val_loss: 0.0630 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0631 - acc: 0.0000e+00 - val_loss: 0.0619 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0620 - acc: 0.0000e+00 - val_loss: 0.0608 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0609 - acc: 0.0000e+00 - val_loss: 0.0596 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0597 - acc: 0.0000e+00 - val_loss: 0.0583 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0584 - acc: 0.0000e+00 - val_loss: 0.0570 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0571 - acc: 0.0000e+00 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0556 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0540 - acc: 0.0000e+00 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0524 - acc: 0.0000e+00 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0507 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.0475 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0448 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0449 - acc: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0421 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0422 - acc: 0.0000e+00 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0410 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0346 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 0.0673 - acc: 0.0000e+00 - val_loss: 0.0665 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 118us/step - loss: 0.0664 - acc: 0.0000e+00 - val_loss: 0.0655 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.0644 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0632 - acc: 0.0000e+00 - val_loss: 0.0622 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0621 - acc: 0.0000e+00 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0609 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0596 - acc: 0.0000e+00 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0583 - acc: 0.0000e+00 - val_loss: 0.0570 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0569 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0553 - acc: 0.0000e+00 - val_loss: 0.0538 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0537 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0521 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0505 - acc: 0.0000e+00 - val_loss: 0.0489 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0489 - acc: 0.0000e+00 - val_loss: 0.0475 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0475 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0451 - acc: 0.0000e+00 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0438 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0425 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0381 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 284us/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 284us/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 0.0674 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 122us/step - loss: 0.0666 - acc: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.0647 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0646 - acc: 0.0000e+00 - val_loss: 0.0636 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0635 - acc: 0.0000e+00 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0623 - acc: 0.0000e+00 - val_loss: 0.0611 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0610 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0596 - acc: 0.0000e+00 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0581 - acc: 0.0000e+00 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0566 - acc: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0550 - acc: 0.0000e+00 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0534 - acc: 0.0000e+00 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0519 - acc: 0.0000e+00 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0504 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0490 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0475 - acc: 0.0000e+00 - val_loss: 0.0462 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0462 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0449 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 63us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0406 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 74us/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0236 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 10ms/step - loss: 0.0682 - acc: 0.0000e+00 - val_loss: 0.0672 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 170us/step - loss: 0.0672 - acc: 0.0000e+00 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0662 - acc: 0.0000e+00 - val_loss: 0.0651 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0651 - acc: 0.0000e+00 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0640 - acc: 0.0000e+00 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0628 - acc: 0.0000e+00 - val_loss: 0.0614 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0614 - acc: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 0.0585 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0569 - acc: 0.0000e+00 - val_loss: 0.0553 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0554 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0539 - acc: 0.0000e+00 - val_loss: 0.0524 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0525 - acc: 0.0000e+00 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0510 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0495 - acc: 0.0000e+00 - val_loss: 0.0480 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0481 - acc: 0.0000e+00 - val_loss: 0.0467 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0467 - acc: 0.0000e+00 - val_loss: 0.0454 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0454 - acc: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0442 - acc: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0431 - acc: 0.0000e+00 - val_loss: 0.0419 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0420 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0410 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0352 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0313 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0307 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0244 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 11ms/step - loss: 0.0680 - acc: 0.0000e+00 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 237us/step - loss: 0.0672 - acc: 0.0000e+00 - val_loss: 0.0663 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0662 - acc: 0.0000e+00 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0651 - acc: 0.0000e+00 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0640 - acc: 0.0000e+00 - val_loss: 0.0629 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0628 - acc: 0.0000e+00 - val_loss: 0.0616 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0614 - acc: 0.0000e+00 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.0571 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0569 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0552 - acc: 0.0000e+00 - val_loss: 0.0538 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0536 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0520 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0505 - acc: 0.0000e+00 - val_loss: 0.0493 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0464 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0462 - acc: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0449 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0425 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0414 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0404 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0394 - acc: 0.0000e+00 - val_loss: 0.0387 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0377 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0233 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0232 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 12ms/step - loss: 0.0685 - acc: 0.0000e+00 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 86us/step - loss: 0.0675 - acc: 0.0000e+00 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0665 - acc: 0.0000e+00 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0655 - acc: 0.0000e+00 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0644 - acc: 0.0000e+00 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0633 - acc: 0.0000e+00 - val_loss: 0.0626 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0620 - acc: 0.0000e+00 - val_loss: 0.0612 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0606 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0592 - acc: 0.0000e+00 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0576 - acc: 0.0000e+00 - val_loss: 0.0565 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0560 - acc: 0.0000e+00 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0543 - acc: 0.0000e+00 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0525 - acc: 0.0000e+00 - val_loss: 0.0514 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0509 - acc: 0.0000e+00 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0494 - acc: 0.0000e+00 - val_loss: 0.0486 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0481 - acc: 0.0000e+00 - val_loss: 0.0473 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.0460 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0455 - acc: 0.0000e+00 - val_loss: 0.0446 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0442 - acc: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0429 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0418 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0387 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0360 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0252 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 13ms/step - loss: 0.0687 - acc: 0.0000e+00 - val_loss: 0.0678 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 93us/step - loss: 0.0677 - acc: 0.0000e+00 - val_loss: 0.0669 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.0658 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0657 - acc: 0.0000e+00 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0645 - acc: 0.0000e+00 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0633 - acc: 0.0000e+00 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0620 - acc: 0.0000e+00 - val_loss: 0.0606 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0605 - acc: 0.0000e+00 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0590 - acc: 0.0000e+00 - val_loss: 0.0575 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0574 - acc: 0.0000e+00 - val_loss: 0.0558 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0558 - acc: 0.0000e+00 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0541 - acc: 0.0000e+00 - val_loss: 0.0526 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0526 - acc: 0.0000e+00 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0512 - acc: 0.0000e+00 - val_loss: 0.0498 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0498 - acc: 0.0000e+00 - val_loss: 0.0483 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0469 - acc: 0.0000e+00 - val_loss: 0.0455 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0456 - acc: 0.0000e+00 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0443 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0432 - acc: 0.0000e+00 - val_loss: 0.0421 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0410 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0411 - acc: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0401 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 116us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0384 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0233 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0687 - acc: 0.0000e+00 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0678 - acc: 0.0000e+00 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0668 - acc: 0.0000e+00 - val_loss: 0.0660 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0658 - acc: 0.0000e+00 - val_loss: 0.0649 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0647 - acc: 0.0000e+00 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0636 - acc: 0.0000e+00 - val_loss: 0.0626 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0624 - acc: 0.0000e+00 - val_loss: 0.0614 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0612 - acc: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0598 - acc: 0.0000e+00 - val_loss: 0.0586 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0584 - acc: 0.0000e+00 - val_loss: 0.0571 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0569 - acc: 0.0000e+00 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0553 - acc: 0.0000e+00 - val_loss: 0.0538 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0536 - acc: 0.0000e+00 - val_loss: 0.0521 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0519 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0488 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0475 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0461 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0435 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0409 - acc: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0349 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 95us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 15ms/step - loss: 0.0698 - acc: 0.0000e+00 - val_loss: 0.0691 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 162us/step - loss: 0.0687 - acc: 0.0000e+00 - val_loss: 0.0681 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0677 - acc: 0.0000e+00 - val_loss: 0.0672 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0657 - acc: 0.0000e+00 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0646 - acc: 0.0000e+00 - val_loss: 0.0639 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0635 - acc: 0.0000e+00 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0623 - acc: 0.0000e+00 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0609 - acc: 0.0000e+00 - val_loss: 0.0599 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0595 - acc: 0.0000e+00 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0580 - acc: 0.0000e+00 - val_loss: 0.0568 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0564 - acc: 0.0000e+00 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0548 - acc: 0.0000e+00 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0532 - acc: 0.0000e+00 - val_loss: 0.0520 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0517 - acc: 0.0000e+00 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0492 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0489 - acc: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0475 - acc: 0.0000e+00 - val_loss: 0.0464 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0461 - acc: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0435 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0423 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0383 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0360 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0346 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 95us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0696 - acc: 0.0000e+00 - val_loss: 0.0684 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 197us/step - loss: 0.0688 - acc: 0.0105 - val_loss: 0.0674 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0677 - acc: 0.0000e+00 - val_loss: 0.0663 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0666 - acc: 0.0000e+00 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0641 - acc: 0.0000e+00 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0626 - acc: 0.0000e+00 - val_loss: 0.0607 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0610 - acc: 0.0000e+00 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0594 - acc: 0.0000e+00 - val_loss: 0.0574 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0577 - acc: 0.0000e+00 - val_loss: 0.0558 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0561 - acc: 0.0000e+00 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0544 - acc: 0.0000e+00 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0529 - acc: 0.0000e+00 - val_loss: 0.0511 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0513 - acc: 0.0000e+00 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0498 - acc: 0.0000e+00 - val_loss: 0.0483 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0459 - acc: 0.0000e+00 - val_loss: 0.0446 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0447 - acc: 0.0000e+00 - val_loss: 0.0435 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0425 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0384 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 1s 16ms/step - loss: 0.0699 - acc: 0.0000e+00 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 253us/step - loss: 0.0689 - acc: 0.0000e+00 - val_loss: 0.0678 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0679 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0668 - acc: 0.0000e+00 - val_loss: 0.0655 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 74us/step - loss: 0.0629 - acc: 0.0000e+00 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0614 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0598 - acc: 0.0000e+00 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0582 - acc: 0.0000e+00 - val_loss: 0.0563 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0564 - acc: 0.0000e+00 - val_loss: 0.0546 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0547 - acc: 0.0000e+00 - val_loss: 0.0530 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0531 - acc: 0.0000e+00 - val_loss: 0.0516 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0517 - acc: 0.0000e+00 - val_loss: 0.0502 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0488 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0489 - acc: 0.0000e+00 - val_loss: 0.0474 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0475 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0461 - acc: 0.0000e+00 - val_loss: 0.0448 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0449 - acc: 0.0000e+00 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0427 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0383 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 284us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 442us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0244 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0702 - acc: 0.0000e+00 - val_loss: 0.0695 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 255us/step - loss: 0.0691 - acc: 0.0000e+00 - val_loss: 0.0684 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0681 - acc: 0.0000e+00 - val_loss: 0.0674 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0671 - acc: 0.0000e+00 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0659 - acc: 0.0000e+00 - val_loss: 0.0649 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0646 - acc: 0.0000e+00 - val_loss: 0.0635 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0632 - acc: 0.0000e+00 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0617 - acc: 0.0000e+00 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0601 - acc: 0.0000e+00 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0584 - acc: 0.0000e+00 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0567 - acc: 0.0000e+00 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0550 - acc: 0.0000e+00 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0534 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0520 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0505 - acc: 0.0000e+00 - val_loss: 0.0492 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0453 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0451 - acc: 0.0000e+00 - val_loss: 0.0442 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0440 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0430 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0411 - acc: 0.0000e+00 - val_loss: 0.0404 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0346 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 19ms/step - loss: 0.0705 - acc: 0.0000e+00 - val_loss: 0.0697 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 225us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0685 - acc: 0.0000e+00 - val_loss: 0.0674 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0673 - acc: 0.0000e+00 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0660 - acc: 0.0000e+00 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0645 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0630 - acc: 0.0000e+00 - val_loss: 0.0614 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0613 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0597 - acc: 0.0000e+00 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0581 - acc: 0.0000e+00 - val_loss: 0.0565 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0565 - acc: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0549 - acc: 0.0000e+00 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0533 - acc: 0.0000e+00 - val_loss: 0.0518 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0518 - acc: 0.0000e+00 - val_loss: 0.0504 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0490 - acc: 0.0000e+00 - val_loss: 0.0477 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0465 - acc: 0.0000e+00 - val_loss: 0.0454 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0454 - acc: 0.0000e+00 - val_loss: 0.0444 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0443 - acc: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0425 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0425 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0416 - acc: 0.0000e+00 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0319 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0307 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.0703 - acc: 0.0000e+00 - val_loss: 0.0695 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 110us/step - loss: 0.0694 - acc: 0.0000e+00 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0684 - acc: 0.0105 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0674 - acc: 0.0000e+00 - val_loss: 0.0665 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0664 - acc: 0.0000e+00 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0652 - acc: 0.0000e+00 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0640 - acc: 0.0000e+00 - val_loss: 0.0629 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0628 - acc: 0.0000e+00 - val_loss: 0.0616 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0615 - acc: 0.0000e+00 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0601 - acc: 0.0000e+00 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0586 - acc: 0.0000e+00 - val_loss: 0.0571 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0570 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0553 - acc: 0.0000e+00 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0536 - acc: 0.0000e+00 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0519 - acc: 0.0000e+00 - val_loss: 0.0503 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0489 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0489 - acc: 0.0000e+00 - val_loss: 0.0477 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0464 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0464 - acc: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0413 - acc: 0.0000e+00 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.0394 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0394 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0386 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0370 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0349 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 20ms/step - loss: 0.0713 - acc: 0.0000e+00 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 198us/step - loss: 0.0701 - acc: 0.0105 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0692 - acc: 0.0105 - val_loss: 0.0684 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0682 - acc: 0.0000e+00 - val_loss: 0.0672 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0670 - acc: 0.0000e+00 - val_loss: 0.0659 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0657 - acc: 0.0000e+00 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0644 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0629 - acc: 0.0000e+00 - val_loss: 0.0616 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0614 - acc: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0598 - acc: 0.0000e+00 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0583 - acc: 0.0000e+00 - val_loss: 0.0568 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0567 - acc: 0.0000e+00 - val_loss: 0.0553 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0552 - acc: 0.0000e+00 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0537 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0522 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0507 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0493 - acc: 0.0000e+00 - val_loss: 0.0481 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0480 - acc: 0.0000e+00 - val_loss: 0.0468 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0456 - acc: 0.0000e+00 - val_loss: 0.0446 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0446 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0435 - acc: 0.0000e+00 - val_loss: 0.0427 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0394 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0393 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0252 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 20ms/step - loss: 0.0712 - acc: 0.0000e+00 - val_loss: 0.0702 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 157us/step - loss: 0.0701 - acc: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0691 - acc: 0.0000e+00 - val_loss: 0.0681 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0680 - acc: 0.0000e+00 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.0655 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0639 - acc: 0.0000e+00 - val_loss: 0.0624 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0623 - acc: 0.0000e+00 - val_loss: 0.0607 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0607 - acc: 0.0000e+00 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0590 - acc: 0.0000e+00 - val_loss: 0.0575 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0574 - acc: 0.0000e+00 - val_loss: 0.0559 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0558 - acc: 0.0000e+00 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0542 - acc: 0.0000e+00 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0527 - acc: 0.0000e+00 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0512 - acc: 0.0000e+00 - val_loss: 0.0498 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0498 - acc: 0.0000e+00 - val_loss: 0.0484 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.0472 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0472 - acc: 0.0000e+00 - val_loss: 0.0460 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0460 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0449 - acc: 0.0000e+00 - val_loss: 0.0439 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0439 - acc: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0430 - acc: 0.0000e+00 - val_loss: 0.0421 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0413 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 23ms/step - loss: 0.0710 - acc: 0.0000e+00 - val_loss: 0.0700 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 149us/step - loss: 0.0701 - acc: 0.0000e+00 - val_loss: 0.0690 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0691 - acc: 0.0000e+00 - val_loss: 0.0679 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0680 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0668 - acc: 0.0000e+00 - val_loss: 0.0655 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0642 - acc: 0.0000e+00 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0628 - acc: 0.0000e+00 - val_loss: 0.0612 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0613 - acc: 0.0000e+00 - val_loss: 0.0595 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0597 - acc: 0.0000e+00 - val_loss: 0.0578 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 84us/step - loss: 0.0580 - acc: 0.0000e+00 - val_loss: 0.0561 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0563 - acc: 0.0000e+00 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0547 - acc: 0.0000e+00 - val_loss: 0.0529 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0532 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0517 - acc: 0.0000e+00 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0485 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0488 - acc: 0.0000e+00 - val_loss: 0.0471 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0474 - acc: 0.0000e+00 - val_loss: 0.0458 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0460 - acc: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0416 - acc: 0.0000e+00 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0406 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0381 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0313 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0307 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0244 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 22ms/step - loss: 0.0714 - acc: 0.0000e+00 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0705 - acc: 0.0000e+00 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0694 - acc: 0.0000e+00 - val_loss: 0.0684 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0682 - acc: 0.0000e+00 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0669 - acc: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0641 - acc: 0.0000e+00 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0625 - acc: 0.0000e+00 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0609 - acc: 0.0000e+00 - val_loss: 0.0594 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0592 - acc: 0.0000e+00 - val_loss: 0.0577 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0576 - acc: 0.0000e+00 - val_loss: 0.0561 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0560 - acc: 0.0000e+00 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0544 - acc: 0.0000e+00 - val_loss: 0.0530 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0529 - acc: 0.0000e+00 - val_loss: 0.0514 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0513 - acc: 0.0000e+00 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0499 - acc: 0.0000e+00 - val_loss: 0.0486 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0485 - acc: 0.0000e+00 - val_loss: 0.0473 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0472 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0460 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0427 - acc: 0.0000e+00 - val_loss: 0.0419 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0383 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 95us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 23ms/step - loss: 0.0716 - acc: 0.0000e+00 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 203us/step - loss: 0.0707 - acc: 0.0000e+00 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0696 - acc: 0.0000e+00 - val_loss: 0.0685 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0685 - acc: 0.0000e+00 - val_loss: 0.0672 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0673 - acc: 0.0000e+00 - val_loss: 0.0659 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0660 - acc: 0.0000e+00 - val_loss: 0.0645 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0646 - acc: 0.0000e+00 - val_loss: 0.0630 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0631 - acc: 0.0000e+00 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0615 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0599 - acc: 0.0000e+00 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0583 - acc: 0.0000e+00 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0567 - acc: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0551 - acc: 0.0000e+00 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0535 - acc: 0.0000e+00 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0520 - acc: 0.0000e+00 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0505 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0464 - acc: 0.0000e+00 - val_loss: 0.0451 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0452 - acc: 0.0000e+00 - val_loss: 0.0439 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0441 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0430 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0420 - acc: 0.0000e+00 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0410 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0401 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0384 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 24ms/step - loss: 0.0717 - acc: 0.0000e+00 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 260us/step - loss: 0.0706 - acc: 0.0000e+00 - val_loss: 0.0694 - val_acc: 0.0312\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0681 - val_acc: 0.0312\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0682 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0312\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.0650 - val_acc: 0.0312\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0651 - acc: 0.0000e+00 - val_loss: 0.0633 - val_acc: 0.0312\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0633 - acc: 0.0000e+00 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0615 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0598 - acc: 0.0000e+00 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0581 - acc: 0.0000e+00 - val_loss: 0.0564 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0565 - acc: 0.0000e+00 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0550 - acc: 0.0000e+00 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 189us/step - loss: 0.0535 - acc: 0.0000e+00 - val_loss: 0.0520 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0521 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0508 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0495 - acc: 0.0000e+00 - val_loss: 0.0483 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.0472 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0473 - acc: 0.0000e+00 - val_loss: 0.0462 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0452 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0454 - acc: 0.0000e+00 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0420 - acc: 0.0000e+00 - val_loss: 0.0410 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0404 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0387 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 105us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 536us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 25ms/step - loss: 0.0719 - acc: 0.0000e+00 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 233us/step - loss: 0.0708 - acc: 0.0000e+00 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0696 - acc: 0.0000e+00 - val_loss: 0.0684 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0685 - acc: 0.0000e+00 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0672 - acc: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0658 - acc: 0.0000e+00 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0642 - acc: 0.0000e+00 - val_loss: 0.0624 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0625 - acc: 0.0000e+00 - val_loss: 0.0607 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0607 - acc: 0.0000e+00 - val_loss: 0.0589 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0590 - acc: 0.0000e+00 - val_loss: 0.0573 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0574 - acc: 0.0000e+00 - val_loss: 0.0558 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0558 - acc: 0.0000e+00 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0544 - acc: 0.0000e+00 - val_loss: 0.0529 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0529 - acc: 0.0000e+00 - val_loss: 0.0514 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0514 - acc: 0.0000e+00 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0500 - acc: 0.0000e+00 - val_loss: 0.0488 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0488 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0465 - acc: 0.0000e+00 - val_loss: 0.0455 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0455 - acc: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0427 - acc: 0.0000e+00 - val_loss: 0.0419 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0419 - acc: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0411 - acc: 0.0000e+00 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0346 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 2s 25ms/step - loss: 0.0725 - acc: 0.0000e+00 - val_loss: 0.0713 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 248us/step - loss: 0.0714 - acc: 0.0000e+00 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0705 - acc: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0694 - acc: 0.0000e+00 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0682 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0668 - acc: 0.0000e+00 - val_loss: 0.0652 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0638 - acc: 0.0000e+00 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0621 - acc: 0.0000e+00 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0603 - acc: 0.0000e+00 - val_loss: 0.0585 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0569 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0554 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0539 - acc: 0.0000e+00 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0523 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0508 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0494 - acc: 0.0000e+00 - val_loss: 0.0482 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0481 - acc: 0.0000e+00 - val_loss: 0.0470 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0470 - acc: 0.0000e+00 - val_loss: 0.0459 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0458 - acc: 0.0000e+00 - val_loss: 0.0448 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0439 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0438 - acc: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0429 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0413 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0384 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0383 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0349 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 27ms/step - loss: 0.0725 - acc: 0.0000e+00 - val_loss: 0.0714 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 219us/step - loss: 0.0714 - acc: 0.0000e+00 - val_loss: 0.0702 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0702 - acc: 0.0000e+00 - val_loss: 0.0690 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0690 - acc: 0.0000e+00 - val_loss: 0.0677 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0677 - acc: 0.0000e+00 - val_loss: 0.0663 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0663 - acc: 0.0000e+00 - val_loss: 0.0648 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0647 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0631 - acc: 0.0000e+00 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0615 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0598 - acc: 0.0000e+00 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0582 - acc: 0.0000e+00 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0567 - acc: 0.0000e+00 - val_loss: 0.0551 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0551 - acc: 0.0000e+00 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0536 - acc: 0.0000e+00 - val_loss: 0.0521 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0521 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0508 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0495 - acc: 0.0000e+00 - val_loss: 0.0482 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0483 - acc: 0.0000e+00 - val_loss: 0.0470 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.0460 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0460 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.0440 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0441 - acc: 0.0000e+00 - val_loss: 0.0431 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0431 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0423 - acc: 0.0000e+00 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0407 - acc: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 400us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0384 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0384 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0377 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0370 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0722 - acc: 0.0000e+00 - val_loss: 0.0709 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 243us/step - loss: 0.0713 - acc: 0.0000e+00 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0701 - acc: 0.0000e+00 - val_loss: 0.0685 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0688 - acc: 0.0000e+00 - val_loss: 0.0672 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0674 - acc: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0659 - acc: 0.0000e+00 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0625 - acc: 0.0000e+00 - val_loss: 0.0606 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0608 - acc: 0.0000e+00 - val_loss: 0.0588 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0590 - acc: 0.0000e+00 - val_loss: 0.0572 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0573 - acc: 0.0000e+00 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0557 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0541 - acc: 0.0000e+00 - val_loss: 0.0524 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0526 - acc: 0.0000e+00 - val_loss: 0.0510 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0511 - acc: 0.0000e+00 - val_loss: 0.0496 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0498 - acc: 0.0000e+00 - val_loss: 0.0484 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0485 - acc: 0.0000e+00 - val_loss: 0.0472 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0473 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0462 - acc: 0.0000e+00 - val_loss: 0.0451 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0452 - acc: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0442 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0433 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0416 - acc: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0384 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0370 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0349 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 368us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0729 - acc: 0.0000e+00 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 272us/step - loss: 0.0718 - acc: 0.0000e+00 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0707 - acc: 0.0000e+00 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0683 - acc: 0.0000e+00 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0670 - acc: 0.0000e+00 - val_loss: 0.0656 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0641 - acc: 0.0000e+00 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0625 - acc: 0.0000e+00 - val_loss: 0.0608 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0608 - acc: 0.0000e+00 - val_loss: 0.0592 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0592 - acc: 0.0000e+00 - val_loss: 0.0577 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0577 - acc: 0.0000e+00 - val_loss: 0.0562 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0562 - acc: 0.0000e+00 - val_loss: 0.0547 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 116us/step - loss: 0.0547 - acc: 0.0000e+00 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0531 - acc: 0.0000e+00 - val_loss: 0.0516 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0516 - acc: 0.0000e+00 - val_loss: 0.0502 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0502 - acc: 0.0000e+00 - val_loss: 0.0489 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0488 - acc: 0.0000e+00 - val_loss: 0.0477 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0464 - acc: 0.0000e+00 - val_loss: 0.0454 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0453 - acc: 0.0000e+00 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0442 - acc: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0432 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0423 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0414 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0360 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 252us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0252 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0732 - acc: 0.0000e+00 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 135us/step - loss: 0.0719 - acc: 0.0000e+00 - val_loss: 0.0707 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0709 - acc: 0.0000e+00 - val_loss: 0.0697 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0699 - acc: 0.0000e+00 - val_loss: 0.0685 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0688 - acc: 0.0000e+00 - val_loss: 0.0674 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0676 - acc: 0.0000e+00 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0664 - acc: 0.0000e+00 - val_loss: 0.0647 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0650 - acc: 0.0000e+00 - val_loss: 0.0632 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0635 - acc: 0.0000e+00 - val_loss: 0.0617 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0619 - acc: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0602 - acc: 0.0000e+00 - val_loss: 0.0583 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0569 - acc: 0.0000e+00 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0554 - acc: 0.0000e+00 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0539 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0524 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0508 - acc: 0.0000e+00 - val_loss: 0.0492 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0494 - acc: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0480 - acc: 0.0000e+00 - val_loss: 0.0466 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0467 - acc: 0.0000e+00 - val_loss: 0.0454 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0455 - acc: 0.0000e+00 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0444 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0406 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0252 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0727 - acc: 0.0000e+00 - val_loss: 0.0720 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 265us/step - loss: 0.0718 - acc: 0.0000e+00 - val_loss: 0.0709 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0707 - acc: 0.0000e+00 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0696 - acc: 0.0000e+00 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0671 - acc: 0.0000e+00 - val_loss: 0.0659 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0658 - acc: 0.0000e+00 - val_loss: 0.0644 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0627 - acc: 0.0000e+00 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0609 - acc: 0.0000e+00 - val_loss: 0.0592 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0591 - acc: 0.0000e+00 - val_loss: 0.0573 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0572 - acc: 0.0000e+00 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0554 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0538 - acc: 0.0000e+00 - val_loss: 0.0525 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 126us/step - loss: 0.0525 - acc: 0.0000e+00 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0511 - acc: 0.0000e+00 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0497 - acc: 0.0000e+00 - val_loss: 0.0482 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0482 - acc: 0.0000e+00 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0457 - acc: 0.0000e+00 - val_loss: 0.0447 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0447 - acc: 0.0000e+00 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.0419 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0419 - acc: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0411 - acc: 0.0000e+00 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0396 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0252 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0732 - acc: 0.0000e+00 - val_loss: 0.0723 - val_acc: 0.0312\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 157us/step - loss: 0.0720 - acc: 0.0000e+00 - val_loss: 0.0713 - val_acc: 0.0312\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0711 - acc: 0.0000e+00 - val_loss: 0.0702 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0700 - acc: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0690 - acc: 0.0000e+00 - val_loss: 0.0681 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0679 - acc: 0.0000e+00 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0668 - acc: 0.0000e+00 - val_loss: 0.0658 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0644 - acc: 0.0000e+00 - val_loss: 0.0633 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0631 - acc: 0.0000e+00 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0618 - acc: 0.0000e+00 - val_loss: 0.0605 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0603 - acc: 0.0000e+00 - val_loss: 0.0590 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0588 - acc: 0.0000e+00 - val_loss: 0.0574 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0572 - acc: 0.0000e+00 - val_loss: 0.0556 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0554 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0537 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0520 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0504 - acc: 0.0000e+00 - val_loss: 0.0493 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.0480 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0466 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0452 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0449 - acc: 0.0000e+00 - val_loss: 0.0439 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0425 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0406 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0732 - acc: 0.0000e+00 - val_loss: 0.0722 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 301us/step - loss: 0.0722 - acc: 0.0000e+00 - val_loss: 0.0711 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0712 - acc: 0.0000e+00 - val_loss: 0.0700 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0700 - acc: 0.0000e+00 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0688 - acc: 0.0000e+00 - val_loss: 0.0674 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0675 - acc: 0.0000e+00 - val_loss: 0.0660 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0661 - acc: 0.0000e+00 - val_loss: 0.0645 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0645 - acc: 0.0000e+00 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0629 - acc: 0.0000e+00 - val_loss: 0.0611 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0611 - acc: 0.0000e+00 - val_loss: 0.0594 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0594 - acc: 0.0000e+00 - val_loss: 0.0577 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0577 - acc: 0.0000e+00 - val_loss: 0.0562 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0562 - acc: 0.0000e+00 - val_loss: 0.0546 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0546 - acc: 0.0000e+00 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0530 - acc: 0.0000e+00 - val_loss: 0.0516 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0515 - acc: 0.0000e+00 - val_loss: 0.0501 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0501 - acc: 0.0000e+00 - val_loss: 0.0488 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0487 - acc: 0.0000e+00 - val_loss: 0.0475 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0475 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0462 - acc: 0.0000e+00 - val_loss: 0.0452 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0451 - acc: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0441 - acc: 0.0000e+00 - val_loss: 0.0431 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0431 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0422 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0413 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0404 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0396 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0381 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0352 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 34ms/step - loss: 0.0732 - acc: 0.0000e+00 - val_loss: 0.0720 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 224us/step - loss: 0.0721 - acc: 0.0000e+00 - val_loss: 0.0709 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0710 - acc: 0.0000e+00 - val_loss: 0.0697 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0698 - acc: 0.0000e+00 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.0669 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0670 - acc: 0.0000e+00 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.0636 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0637 - acc: 0.0000e+00 - val_loss: 0.0619 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0620 - acc: 0.0000e+00 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0603 - acc: 0.0000e+00 - val_loss: 0.0586 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0587 - acc: 0.0000e+00 - val_loss: 0.0570 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0571 - acc: 0.0000e+00 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0555 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0540 - acc: 0.0000e+00 - val_loss: 0.0525 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0525 - acc: 0.0000e+00 - val_loss: 0.0511 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0511 - acc: 0.0000e+00 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0498 - acc: 0.0000e+00 - val_loss: 0.0485 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0485 - acc: 0.0000e+00 - val_loss: 0.0473 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0473 - acc: 0.0000e+00 - val_loss: 0.0462 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0462 - acc: 0.0000e+00 - val_loss: 0.0451 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0451 - acc: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0441 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0431 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0422 - acc: 0.0000e+00 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0414 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0397 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0360 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 34ms/step - loss: 0.0737 - acc: 0.0000e+00 - val_loss: 0.0730 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 252us/step - loss: 0.0727 - acc: 0.0000e+00 - val_loss: 0.0719 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0716 - acc: 0.0000e+00 - val_loss: 0.0709 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0706 - acc: 0.0000e+00 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0683 - acc: 0.0000e+00 - val_loss: 0.0674 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0671 - acc: 0.0000e+00 - val_loss: 0.0660 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0657 - acc: 0.0000e+00 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 137us/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0628 - acc: 0.0000e+00 - val_loss: 0.0614 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0611 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0594 - acc: 0.0000e+00 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0577 - acc: 0.0000e+00 - val_loss: 0.0564 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0561 - acc: 0.0000e+00 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0547 - acc: 0.0000e+00 - val_loss: 0.0535 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0533 - acc: 0.0000e+00 - val_loss: 0.0521 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0519 - acc: 0.0000e+00 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0504 - acc: 0.0000e+00 - val_loss: 0.0492 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0490 - acc: 0.0000e+00 - val_loss: 0.0479 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0467 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0465 - acc: 0.0000e+00 - val_loss: 0.0456 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0454 - acc: 0.0000e+00 - val_loss: 0.0446 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0444 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0416 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0407 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0384 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0377 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0370 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0313 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0307 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 37ms/step - loss: 0.0736 - acc: 0.0000e+00 - val_loss: 0.0724 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 340us/step - loss: 0.0723 - acc: 0.0000e+00 - val_loss: 0.0713 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0712 - acc: 0.0000e+00 - val_loss: 0.0702 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0701 - acc: 0.0000e+00 - val_loss: 0.0690 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0689 - acc: 0.0000e+00 - val_loss: 0.0676 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0675 - acc: 0.0000e+00 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0660 - acc: 0.0000e+00 - val_loss: 0.0645 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0644 - acc: 0.0000e+00 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0626 - acc: 0.0000e+00 - val_loss: 0.0609 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0607 - acc: 0.0000e+00 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0589 - acc: 0.0000e+00 - val_loss: 0.0575 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0573 - acc: 0.0000e+00 - val_loss: 0.0560 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0558 - acc: 0.0000e+00 - val_loss: 0.0546 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0544 - acc: 0.0000e+00 - val_loss: 0.0530 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0529 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0513 - acc: 0.0000e+00 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0499 - acc: 0.0000e+00 - val_loss: 0.0487 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0486 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0474 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0455 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0453 - acc: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0444 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0435 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0418 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0411 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0381 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0360 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 40ms/step - loss: 0.0738 - acc: 0.0105 - val_loss: 0.0729 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 191us/step - loss: 0.0729 - acc: 0.0000e+00 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0717 - acc: 0.0000e+00 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0705 - acc: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0691 - acc: 0.0000e+00 - val_loss: 0.0676 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0676 - acc: 0.0000e+00 - val_loss: 0.0660 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0659 - acc: 0.0000e+00 - val_loss: 0.0644 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0626 - acc: 0.0000e+00 - val_loss: 0.0611 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0610 - acc: 0.0000e+00 - val_loss: 0.0595 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0594 - acc: 0.0000e+00 - val_loss: 0.0578 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0578 - acc: 0.0000e+00 - val_loss: 0.0562 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0562 - acc: 0.0000e+00 - val_loss: 0.0546 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0546 - acc: 0.0000e+00 - val_loss: 0.0532 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0531 - acc: 0.0000e+00 - val_loss: 0.0517 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0517 - acc: 0.0000e+00 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0504 - acc: 0.0000e+00 - val_loss: 0.0491 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.0479 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0479 - acc: 0.0000e+00 - val_loss: 0.0468 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0457 - acc: 0.0000e+00 - val_loss: 0.0446 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0447 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0427 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0419 - acc: 0.0000e+00 - val_loss: 0.0410 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0410 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0394 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0386 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0379 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0252 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 3s 37ms/step - loss: 0.0737 - acc: 0.0000e+00 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 176us/step - loss: 0.0727 - acc: 0.0000e+00 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0717 - acc: 0.0000e+00 - val_loss: 0.0707 - val_acc: 0.0625\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0706 - acc: 0.0211 - val_loss: 0.0695 - val_acc: 0.0625\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0695 - acc: 0.0211 - val_loss: 0.0683 - val_acc: 0.0625\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0683 - acc: 0.0211 - val_loss: 0.0671 - val_acc: 0.0312\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0670 - acc: 0.0105 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0657 - acc: 0.0000e+00 - val_loss: 0.0644 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.0629 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0629 - acc: 0.0000e+00 - val_loss: 0.0614 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 147us/step - loss: 0.0614 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0598 - acc: 0.0000e+00 - val_loss: 0.0581 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0581 - acc: 0.0000e+00 - val_loss: 0.0564 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0565 - acc: 0.0000e+00 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0548 - acc: 0.0000e+00 - val_loss: 0.0533 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0533 - acc: 0.0000e+00 - val_loss: 0.0518 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0519 - acc: 0.0000e+00 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0505 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.0475 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0462 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0439 - acc: 0.0000e+00 - val_loss: 0.0427 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0407 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0381 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 37ms/step - loss: 0.0737 - acc: 0.0211 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 172us/step - loss: 0.0728 - acc: 0.0000e+00 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0718 - acc: 0.0000e+00 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0707 - acc: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0679 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0682 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0670 - acc: 0.0000e+00 - val_loss: 0.0654 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0642 - acc: 0.0000e+00 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0628 - acc: 0.0000e+00 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0612 - acc: 0.0000e+00 - val_loss: 0.0593 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0596 - acc: 0.0000e+00 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 263us/step - loss: 0.0579 - acc: 0.0000e+00 - val_loss: 0.0560 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0561 - acc: 0.0000e+00 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0545 - acc: 0.0000e+00 - val_loss: 0.0529 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0530 - acc: 0.0000e+00 - val_loss: 0.0514 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0515 - acc: 0.0000e+00 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0500 - acc: 0.0000e+00 - val_loss: 0.0485 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0485 - acc: 0.0000e+00 - val_loss: 0.0470 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0470 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0457 - acc: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0433 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0422 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0394 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0393 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0377 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 39ms/step - loss: 0.0738 - acc: 0.0000e+00 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 202us/step - loss: 0.0728 - acc: 0.0000e+00 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0718 - acc: 0.0000e+00 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0707 - acc: 0.0000e+00 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0682 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0683 - acc: 0.0000e+00 - val_loss: 0.0669 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0669 - acc: 0.0000e+00 - val_loss: 0.0655 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0655 - acc: 0.0000e+00 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0641 - acc: 0.0000e+00 - val_loss: 0.0624 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0625 - acc: 0.0000e+00 - val_loss: 0.0608 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0608 - acc: 0.0000e+00 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0592 - acc: 0.0000e+00 - val_loss: 0.0575 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0575 - acc: 0.0000e+00 - val_loss: 0.0558 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0559 - acc: 0.0000e+00 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0543 - acc: 0.0000e+00 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0527 - acc: 0.0000e+00 - val_loss: 0.0511 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 252us/step - loss: 0.0512 - acc: 0.0000e+00 - val_loss: 0.0496 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0497 - acc: 0.0000e+00 - val_loss: 0.0482 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0482 - acc: 0.0000e+00 - val_loss: 0.0468 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0469 - acc: 0.0000e+00 - val_loss: 0.0456 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0457 - acc: 0.0000e+00 - val_loss: 0.0444 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0423 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0413 - acc: 0.0000e+00 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0404 - acc: 0.0000e+00 - val_loss: 0.0394 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0387 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0379 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 41ms/step - loss: 0.0742 - acc: 0.0000e+00 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 337us/step - loss: 0.0732 - acc: 0.0000e+00 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0721 - acc: 0.0000e+00 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0710 - acc: 0.0000e+00 - val_loss: 0.0693 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0697 - acc: 0.0000e+00 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.0666 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0669 - acc: 0.0000e+00 - val_loss: 0.0651 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0638 - acc: 0.0000e+00 - val_loss: 0.0618 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0621 - acc: 0.0000e+00 - val_loss: 0.0601 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0604 - acc: 0.0000e+00 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0587 - acc: 0.0000e+00 - val_loss: 0.0568 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0570 - acc: 0.0000e+00 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0554 - acc: 0.0000e+00 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0539 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0524 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0509 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0495 - acc: 0.0000e+00 - val_loss: 0.0481 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0482 - acc: 0.0000e+00 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0469 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0457 - acc: 0.0000e+00 - val_loss: 0.0446 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0446 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0416 - acc: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0407 - acc: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0352 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0319 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0313 - acc: 0.0000e+00 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0307 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 42ms/step - loss: 0.0745 - acc: 0.0000e+00 - val_loss: 0.0733 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 325us/step - loss: 0.0733 - acc: 0.0000e+00 - val_loss: 0.0722 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 242us/step - loss: 0.0722 - acc: 0.0000e+00 - val_loss: 0.0710 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0710 - acc: 0.0000e+00 - val_loss: 0.0697 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0697 - acc: 0.0000e+00 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.0669 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0669 - acc: 0.0000e+00 - val_loss: 0.0652 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0652 - acc: 0.0000e+00 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0635 - acc: 0.0000e+00 - val_loss: 0.0618 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0617 - acc: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0583 - acc: 0.0000e+00 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0568 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0553 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0537 - acc: 0.0000e+00 - val_loss: 0.0524 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0522 - acc: 0.0000e+00 - val_loss: 0.0510 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0508 - acc: 0.0000e+00 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0495 - acc: 0.0000e+00 - val_loss: 0.0485 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0483 - acc: 0.0000e+00 - val_loss: 0.0473 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0460 - acc: 0.0000e+00 - val_loss: 0.0452 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0440 - acc: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0431 - acc: 0.0000e+00 - val_loss: 0.0425 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0422 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0414 - acc: 0.0000e+00 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 42ms/step - loss: 0.0741 - acc: 0.0000e+00 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 334us/step - loss: 0.0732 - acc: 0.0000e+00 - val_loss: 0.0720 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0721 - acc: 0.0000e+00 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0708 - acc: 0.0000e+00 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 178us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0681 - acc: 0.0000e+00 - val_loss: 0.0665 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0666 - acc: 0.0000e+00 - val_loss: 0.0649 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0650 - acc: 0.0000e+00 - val_loss: 0.0632 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0632 - acc: 0.0000e+00 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0615 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0597 - acc: 0.0000e+00 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0580 - acc: 0.0000e+00 - val_loss: 0.0564 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0564 - acc: 0.0000e+00 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0547 - acc: 0.0000e+00 - val_loss: 0.0532 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0531 - acc: 0.0000e+00 - val_loss: 0.0517 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0516 - acc: 0.0000e+00 - val_loss: 0.0503 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0502 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0489 - acc: 0.0000e+00 - val_loss: 0.0477 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0464 - acc: 0.0000e+00 - val_loss: 0.0453 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0452 - acc: 0.0000e+00 - val_loss: 0.0442 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0441 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0431 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0404 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0404 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0387 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 158us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 263us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 400us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 42ms/step - loss: 0.0742 - acc: 0.0000e+00 - val_loss: 0.0734 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 285us/step - loss: 0.0733 - acc: 0.0000e+00 - val_loss: 0.0722 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0721 - acc: 0.0000e+00 - val_loss: 0.0709 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0708 - acc: 0.0000e+00 - val_loss: 0.0695 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0680 - acc: 0.0000e+00 - val_loss: 0.0665 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0664 - acc: 0.0000e+00 - val_loss: 0.0648 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0648 - acc: 0.0000e+00 - val_loss: 0.0632 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0631 - acc: 0.0000e+00 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0615 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0599 - acc: 0.0000e+00 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0582 - acc: 0.0000e+00 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0566 - acc: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0550 - acc: 0.0000e+00 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0535 - acc: 0.0000e+00 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0520 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0506 - acc: 0.0000e+00 - val_loss: 0.0491 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0492 - acc: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0479 - acc: 0.0000e+00 - val_loss: 0.0466 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0467 - acc: 0.0000e+00 - val_loss: 0.0455 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0456 - acc: 0.0000e+00 - val_loss: 0.0444 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0425 - acc: 0.0000e+00 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0407 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 168us/step - loss: 0.0352 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 242us/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 44ms/step - loss: 0.0745 - acc: 0.0000e+00 - val_loss: 0.0736 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0733 - acc: 0.0000e+00 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0722 - acc: 0.0211 - val_loss: 0.0713 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0710 - acc: 0.0000e+00 - val_loss: 0.0701 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0698 - acc: 0.0000e+00 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0685 - acc: 0.0000e+00 - val_loss: 0.0673 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0670 - acc: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.0639 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0637 - acc: 0.0000e+00 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0619 - acc: 0.0000e+00 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 0.0585 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0583 - acc: 0.0000e+00 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0567 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0552 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0537 - acc: 0.0000e+00 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0522 - acc: 0.0000e+00 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0507 - acc: 0.0000e+00 - val_loss: 0.0496 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0494 - acc: 0.0000e+00 - val_loss: 0.0484 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0482 - acc: 0.0000e+00 - val_loss: 0.0473 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.0462 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0460 - acc: 0.0000e+00 - val_loss: 0.0452 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.0442 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0441 - acc: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0432 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0416 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0394 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0387 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 242us/step - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 252us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 252us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 242us/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#   This method cleans the remnant files from the last run\n",
    "clean()\n",
    "\n",
    "#   Here, we define the parameters and values to investiate\n",
    "latent_list = range(10,100,2)\n",
    "test_params = [{'latent':latent_list}]\n",
    "\n",
    "#   Perform sensitivity analysis\n",
    "file = test(test_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post\n",
    "\n",
    "# 1st Plot - compression time vs latent space dimension'\n",
    "\n",
    "This module includes post processing functions and plots the sensitivity analysis results.\n",
    "Let's plot compression data loss (%) per latent space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAJcCAYAAAC8BpYTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4FWX+/vH7k0JCCS2h9957V7D3tbsWEBUF1F3XsvatltXvuta1rbtWpKvYxa64VgIJvTcJPUAgJCGkP78/zsAviykHyMnkJO/XdeVKcmbOzD1zDiF3ZuYZc84JAAAAABA+IvwOAAAAAAA4MhQ5AAAAAAgzFDkAAAAACDMUOQAAAAAIMxQ5AAAAAAgzFDkAAAAACDMUOQA1lpm1NzNnZlF+Z6lOzOxKM/u8ktb1RzN7uTLWVRHM7Bszm+B3jurA+7fb2fv632b2F78zHWRmbc0sy8wi/c4CoPqiyAGoEszsd2aWZGa5ZjbpCJ630cxOK2P6SWZW5P1SlWlmq83s2qPId7+ZTT3S59VEzrlpzrkzKnq53mu55bB1/Z9zrloWo/Le20e4rGr9Rwvn3I3Oub/5neMg59wm51w951yh31kAVF/V8gc6gLC0TdJDks6UVLuil+2ca21mJukCSbPMLFFSdgWvJ+yYWZRzrsDvHAAA4MhwRA5AleCce8c5956ktMOnmVmCmX1kZulmtsfMvjOzCDObIqmtpA+9I253l7MO561jr6SeJaynpZl94K1jnZlN9B4/S9IfJV3urWfx0WyjmdU2syfMLMXM9pnZ92ZW25t2vpkt97bxGzPrUex5G83sLjNbYmb7zewVM2tmZp94Rxm/NLNG3rwHj7xcb2bbzGy7md1RbFn3m9ksM5tqZhmSxnn78l4zW29maWb2ppk19uaP9eZN87LNN7Nm3rRxZrbBy/CzmV1Z7PHvi63zOO95+7zPxxWb9o2Z/c3MfvCW87mZJZSw7+pK+kRSS+81yPJer0NHSott+7VmttnM9prZjWY2xNt36Wb23GHLvc7MVnrzfmZm7Up57T41s98d9thiM7vYAp4ys53eNi4xs95BvB86mdnX3r7dbWbTzKyhN63E97aZDTezH71tWWxmJwW5L7/1Pqd7yxtRQp6hFjgqnmFmqWb25GH7tbT31FAz+8nLtN3MnjOzWsWm9zKzLyzw7yrVzP7oPV7q+66U/XWXt/xtZnbdYdMmmdlD3tcnmdkWM7vbe022m9mFZnaOma3xcvyx2HPLev8f3PZrzGyT9zr96Qj2WZT3fYk/W7xp93vrnOy9bsvNbHBp+wEADnHO8cEHH3xUmQ8FjspNOuyxv0v6t6Ro72OUJPOmbZR0WhnLO0nSFu/rCEkXScqX1E1Se0lOUpQ3/b+S/iUpVlJ/SbsknepNu1/S1GPctuclfSOplaRIScdJipHUVdJ+Sad723e3pHWSahXbxrmSmnnP3SlpgaQB3vO/lnSfN+/BbZohqa6kPt52nFZsO/IlXejtj9qSbvOW39pb3n8kzfDmv0HSh5LqeJkHSarvLTtDUjdvvhaSenlfj5P0vfd1YwWK81UKnAUy2vs+3pv+jaT13j6o7X3/SHmvZbHHDr0uxbb9395reIakHEnvSWpabN+d6M1/obefe3jZ/izpx1LWfbWkH4p931NSure/zpSULKmhJPOW16KU5XwjaYL3dWfvNY+R1ESBsvXPYvNuVLH3tpc/TdI53mt3uvd9k/L2pQ57r5eS7SdJV3lf15M0PMj31CBJw7192F7SSkm3edPiJG2XdIf3msRJGuZNK/V9V0K2sySlSurtZZjuZersTZ8k6aFi75MCSX9V4N/TRC/vdG/9vbz3RcfychTb9pe8fdpPUq6kHkHus2B/tuR4r2ukAj/v5vr9s5gPPvio+h8ckQMQDvIVKArtnHP5zrnvnHPuCJ7f0szSJe2WdJ8Cv3itLj6DmbWRNFLSPc65HOfcIkkvK1BAjpmZRUi6TtKtzrmtzrlC59yPzrlcSZdLmu2c+8I5ly/pcQV+aTyu2CKedc6lOue2SvpOUqJzbqH3/HcVKHXFPeCc2++cWyrpNQUK1EE/Oefec84VOecOKFDW/uSc2+It735Jv/aOJuRLilfgF+ZC51yycy7DW06RpN5mVts5t905t7yETf+VpLXOuSnOuQLn3AxJqySdV2ye15xza7wsbyrwi+6x+Jv3Gn6uQEGe4ZzbWWzfHdxXN0j6u3NupQucXvp/kvqXclTu3cOmXSnpHW9/5StQELor8AeGlc657eWFdM6t817zXOfcLklPSjqxjKeMlfSxc+5j77X7QlKSAgXgoGPZl/mSOptZgnMuyzk397DpJb6nvPfEXO/13ahAETq4HedK2uGce8J7TTKdc4netLLed4e7zNu2Zc65/d685W3Lw96/p5mSEiQ97a1/uaTlkvoeQY4HnHMHnHOLJS1WoNAFs8+C/dnyvfe6FkqaUmz5AFAqihyAcPCYAkdOPrfAqXz3HuHztznnGjrnGjvn+jvnZpYwT0tJe5xzmcUeS1HgKEi5LDBS48FT/j4pYZYEBf4av76Udacc/MY5VyRp82HrTi329YESvq932DI3F/s6xVtHSdMkqZ2kd71T49IVOKJSqMARwCmSPpM00zul7VEzi/Z+mb5c0o2StpvZbDPrXt62FctTfNt2FPs6u4RtOVLB7qt2kp4utt17FDii9ovX3HtfzJZ0hffQFZKmedO+lvScAkdcU83sRTOrX15IM2tqZjPNbKsFTnOdqsD7pDTtJF16MK+XeaQCf+Q46Fj25XgFjuatssApsOceNr3E95SZdbXAqc87vO34v2Lb0UYlv+cPbk9p77vDtSxh/WVJc/9/oJED3uey3gfl5Shtv5a3zw5mL+9ny+HLjy2l0ALAIRQ5AFWe91f0O5xzHRU4knO7mZ16cHIFrWabpMZmFlfssbaStgazHhcYqbGe93F2CbPsVuD0qU6lrPvQUSAzMwV+Ad5awrzBalPs67beOg7FPWzezZLO9sruwY9Y78hhvnPuAedcTwWOEJ6rwGmGcs595pw7XYEisUqB08/K3LZieY5m2yrqtT5os6QbDtvu2s65H0uZf4ak0Ra4vqy2pDmHgjn3jHNukAKn7XWVdFcQ6/+7AtvU1zlXX4EjblZsekmv05TD8tZ1zj0SxLrK3XfOubXOudEKnIb6DwUGBapbbJbS3lMvKPD6d/G244/FtmOzSn7PH5xW4vuuhHm3l7D+inIkOf5HEPtMKv9nCwAcFYocgCrBzKLMLFaBa0QiLTDIxsGBAs41s85ewclQ4K/lB//aniqp47Gu3zm3WdKPkv7urbuvAn9tn1ZsPe29UySPZvlFkl6V9KQ38EGkmY0wsxgFToH7lZmdambRClxPlOvlOVp/MbM6ZtZL0rWS3ihj3n9LevjgaYNm1sTMLvC+PtnM+ljgflgZCpxKVmiBwVbO935pzZWUpf//mhT3saSuZjbGe40vV+D6so+OYptSJcWbWYOjeG5J/i3pD94+kpk1MLNLy5j/YwVK6YOS3vBeU1lgMJVh3mu3X4HCHsyw83EK7Ld0M2ulX5a/w9/bUyWdZ2Zneu+fWAsM7NE6iHXtUuBU2FL/rZjZWDNr4m1Xuvdw8e0o7T0Vp8B7I8s7KvubYs/5SFJzM7vNzGLMLM7MhnnTSn3fleBNBQbm6WlmdRQ4RbqiHEmO/xHEPgvmZwsAHBWKHICq4s8KnO50rwJHJg54j0lSF0lfKvBL70+S/uWc+8ab9ndJf/ZOi7rzGDOMVmCQgm0KXBN1n3cdkiS95X1OM7MFR7n8OyUtlTRfgdP4/iEpwgWu1xsr6VkFjtydJ+k851zeUa5HCgyusE7SV5Ie964XK83Tkj5Q4NTVTAUGfjj4y3ZzSbMU+EV9pbfcqQr8/3GHAvtqjwLXRP328AU759IUOIp3hwIDc9wt6Vzn3O4j3SDn3CoFjopt8F7vluU9p5zlvavAazDTOyVwmaSSjqYenD9X0juSTlNg4IyD6itwNHKvAqfMpSlwnWN5HpA0UNI+BU7bfOew6f/z3vYKwQUKHPHapcCRpLsUxP/lzrlsSQ9L+sFb3vASZjtL0nIzy1LgPXGFcy6n2PTS3lN3ShojKVOB/XDojwbe6YSnK/Ce3iFpraSTvcllve8Oz/+JpH8qMLDPOu9zRQk6RwnK22cHlfWzBQCOysFR3wAA1YCZtZf0s6Rox/3hUAF4TwFA1cQROQAAAAAIMxQ5AAAAAAgznFoJAAAAAGGGI3IAAAAAEGaq1M0mExISXPv27f2OAQAAAAC+SE5O3u2ca1LefFWqyLVv315JSUl+xwAAAAAAX5hZSjDzcWolAAAAAIQZihwAAAAAhBmKHAAAAACEmSp1jRwAAAAAVBf5+fnasmWLcnJyfjEtNjZWrVu3VnR09FEtmyIHAAAAACGwZcsWxcXFqX379jKzQ48755SWlqYtW7aoQ4cOR7VsTq0EAAAAgBDIyclRfHz8/5Q4STIzxcfHl3ikLlgUOQAAAAAIkcNLXHmPB4siBwAAAABhhiIHAAAAAGGGIgcAAAAAIeKcO6LHg0WRAwAAAIAQiI2NVVpa2i9K28FRK2NjY4962dx+AAAAAABCoHXr1tqyZYt27dr1i2kH7yN3tChyAAAAABAC0dHRR32fuPJwaiUAAAAAhBmKHAAAAACEGYocAAAAAIQZihwAAAAAhBmKHAAAAACEGYocAAAAAIQZihwAAAAAhBmKHAAAAACEGYocAAAAgBolr6DI7wjHjCIHAAAAoMZYvm2fTnpsjpI27vE7yjGhyAEAAACoEdbtzNLVr8yTJDVvEOtzmmNDkQMAAABQ7W3ek62xLyfKTJo6YZhaN6rjd6RjQpEDAAAAUK2lZuToypcTlZ1XoCnjh6ljk3p+RzpmUX4HAAAAAIBQ2bM/T2NfTtTurFxNmzBMPVrU9ztShaDIAQAAAKiWMnPydc2r85SyJ1uTrh2iAW0b+R2pwnBqJQAAAIBq50BeocZPStLK7Rl64cqBOq5Tgt+RKhRH5AAAAABUK7kFhbpharLmp+zRM1cM0Kk9mvkdqcJxRA4AAABAtVFQWKTbZi7St2t26ZGL++i8fi39jhQSFDkAAAAA1UJRkdM9by/VJ8t26C/n9tTlQ9r6HSlkKHIAAAAAwp5zTg98uFxvL9ii20/vqvEjO/gdKaRCVuTMrJuZLSr2kWFmt4VqfQAAAABqrsc+W63Xf0rR9Sd01M2ndPY7TsiFbLAT59xqSf0lycwiJW2V9G6o1gcAAACgZnp+zjr965v1Gj20rf5wdneZmd+RQq6yTq08VdJ651xKJa0PAAAAQA0w+aeNeuyz1bqgf0s9dGHvGlHipMorcldImlHSBDO73sySzCxp165dlRQHAAAAQLiblbxFf31/uU7r0UyPX9pPkRE1o8RJlVDkzKyWpPMlvVXSdOfci865wc65wU2aNAl1HAAAAADVwCdLt+vuWYt1fOd4PTdmgKIja9Y4jpWxtWdLWuCcS62EdQEAAACo5v67ZpdumblQ/ds01ItXDVZsdKTfkSpdZRS50SrltEoAAAAAOBLzft6jG6YkqUvTOL127VDVjQnZ+I1VWkiLnJnVkXS6pHdCuR4AAAAA1V/ihjRdN2m+Wjasrcnjh6pB7Wi/I/kmpPXVOZctKT6U6wAAAABQvR3IK9Tjn6/Wqz/8rLaN62jahGFKqBfjdyxf1czjkAAAAADCwvyNe3TXW4u1MS1bVw1vp3vO7q56NfR0yuLYAwAAAACqnAN5hXr0s1Wa9ONGtWpYW9MnDtNxnRL8jlVlUOQAAAAAVCmJG9J099tLlJKWratHtNM9Z3WvsYOalIa9AQAAAKBKyM4r0KOfrtakHzeqTePamjFxuEZ0YsiNklDkAAAAAPhu7oY03T1riTbtyda449rr7rO6qU4t6kpp2DMAAAAAfLM/t0CPfrpKr/+UoraN62jm9cM1vCNH4cpDkQMAAADgi5/Wp+nutxdr854DHIU7QuwlAAAAAJVqf26BHvlklabMTVG7+Dp64/rhGsZRuCNCkQMAAABQaX5ct1t3v71EW9MP6LrjO+iuM7updq1Iv2OFHYocAAAAgJDLyi3QI5+s1NS5m9Qhoa7evGGEhrRv7HessEWRAwAAABAy+YVFeitpi57+ao12ZuZqwsgOuuMMjsIdK4ocAAAAgApXVOT08bLteuLzNfp5934NatdI/7pykAa1a+R3tGqBIgcAAACgwjjn9O3a3Xrss1VatjVD3ZrF6eWrB+vUHk1lZn7HqzYocgAAAAAqxIJNe/Xop6s0d8MetW5UW09e1k8X9G+lyAgKXEWjyAEAAAA4JmtTM/XYZ6v1+YpUJdSrpQfO76UrhrZRTBTXwYUKRQ4AAADAUdmyN1v//HKt3lmwRXVqRemO07vqupEdVDeGmhFq7GEAAAAARyQtK1fPz1mvqXNTJJPGj+yg35zUWY3r1vI7Wo1BkQMAAAAQlKzcAr383Qa99O0GHcgv1KWD2ujW07qoZcPafkercShyAAAAAMqUW1CoqXM36fk567Rnf57O7t1cd5zRTZ2b1vM7Wo1FkQMAAABQop0ZOXozabOmJ27Stn05Or5zvO4+s7v6tWnod7QajyIHAAAA4JCiIqcf1u/W9MRN+mJFqgqKnI7rFK9Hf91PI7sk+B0PHoocAAAAAO3OytWs5C2aMW+TUtKy1ahOtK49vr1GD22rjk04hbKqocgBAAAANZRzTnM37NG0xBR9tnyH8gudhrZvrNtP76ozezVXbDT3gauqKHIAAABADZOenadZyVs0fd4mbdi1X/VjozR2eDuNGdpWXZrF+R0PQaDIAQAAADWAc07JKXs1PXGTPlq6XXkFRRrYtqEev7Sfzu3bgqNvYYYiBwAAAFRj+w7k672FWzU9cZNWp2aqXkyULh/cRmOGtVWPFvX9joejRJEDAAAAqqmZ8zbpgQ9X6EB+ofq2bqB/XNJH5/VrqTq1qAHhjlcQAAAAqGacc3rmq3V66ss1GtUlQfec1V29WzXwOxYqEEUOAAAAqEYKi5z+8v4yTU/cpF8Paq2/X9xH0ZERfsdCBaPIAQAAANVETn6hbp6xUF+sSNVNJ3fSnWd0k5n5HQshQJEDAAAAqoH07DyNfz1JCzbt1QPn99I1x7X3OxJCiCIHAAAAhLmt6Qd0zavztCktW8+PGahz+rTwOxJCjCIHAAAAhLHVOzJ1zavztD+vQJPHD9XwjvF+R0IloMgBAAAAYSpxQ5omTE5SnVqReuvGEerenPvC1RQUOQAAACAMfbJ0u259Y5HaNKqtyeOHqVXD2n5HQiWiyAEAAABhZspPG/XXD5ZrQJuGeuWaIWpUt5bfkVDJKHIAAABAmHDO6fHPV+v5Oet1Wo9menb0ANWuFel3LPiAIgcAAACEgfzCIv3xnaV6K3mLRg9to79d0FtR3Oi7xqLIAQAAAFVcdl6Bbpq2QHNW79Ktp3bRbad14UbfNRxFDgAAAKjC9uzP07WT5mvplnQ9fFFvXTmsnd+RUAVQ5AAAAIAqavOebF3z6jxtTT+gf48dpDN6Nfc7EqoIihwAAABQBa3YlqFrXpunvIIiTZswTIPbN/Y7EqoQihwAAABQxazYlqHRL81VnVqRmn7jCHVpFud3JFQxFDkAAACgClm9I1NjX0lUnVqRevOGEWrTuI7fkVAFMV4pAAAAUEWs25mpK1+eq+hI04yJwylxKBVFDgAAAKgCNuzK0uiXEiWZpk8crvYJdf2OhCqMIgcAAAD4LCVtv8a8lKiiIqcZE4epU5N6fkdCFcc1cgAAAICPNu/J1piXEpVTUKgZE4czsAmCwhE5AAAAwCfb0g9ozMtzlZmTr6njh6lHi/p+R0KYoMgBAAAAPkjNyNGYl+YqfX++powfpt6tGvgdCWGEIgcAAABUsp2ZORr90lztyszVpOuGql+bhn5HQpjhGjkAAACgEqVl5erKlxK1PT1Hk8cP1aB2jfyOhDDEETkAAACgkuzdn6crX07U5r3ZenXcEA1p39jvSAhTHJEDAAAAKsG+7HyNfSVRG3bv16vXDNGITvF+R0IY44gcAAAAEGIZOfm6+tVErU3N0otXDdLILgl+R0KYo8gBAAAAIZSVW6Bxr87T8m0Z+teVA3VSt6Z+R0I1wKmVAAAAQIhk5xXoutfma/GWfXp+zACd1rOZ35FQTXBEDgAAAAiBA3mFGj8pSUkpe/T0Ff11Vu8WfkdCNcIROQAAAKCC5eQX6vopSZr7c5qeuqy/zu3b0u9IqGY4IgcAAABUoIycfF0/JVnfr9utRy/pqwsHtPI7EqohjsgBAAAAFWT1jkzdODVZm/Zk65GL++jSwW38joRqiiIHAAAAVID3F23VvW8vVb3YKM2YOFxDO3Czb4QORQ4AAAA4BnkFRfq/j1dq0o8bNaR9Iz0/ZqCa1o/1OxaqOYocAAAAqgXnnJyTIiKs0ta5Y1+Obpq+QMkpezV+ZAfde3Z3RUcyDAVCjyIHAACAauHh2Sv1ZtJmTRjVUdce315xsdEhXd9P69N084wFys4r1HNjBjAyJSoVfy4AAABA2Fu2dZ9e/eFnNagTrSe/WKNRj87RC9+sV3ZeQYWvyzmnF79dr7GvJKp+7Wi9f9PxlDhUOo7IAQAAIKw553TfB8vVqE4tfXTzKKWk7deTX6zRPz5dpVe+36AbT+ykscPbKTY68pjXlZmTr7tnLdEny3bo7N7N9eiv+4b8yB9QEo7IAQAAIKy9u3CrklP26p6zuqtB7Wj1bd1Qk64dqrd/M0LdmsfpodkrdeJjczT5p43KLSg86vWsSc3UBc//oM9XpOpP5/TQv64cSImDb8w553eGQwYPHuySkpL8jgEAAIAwkZmTr1Oe+K9aNqytd39zXIkDnczdkKYnP1+jeRv3qFXD2vrdKZ3160Gtj2hQkg8Xb9M9by9RnVqRem7MQA3vGF+RmwEcYmbJzrnB5c3HETkAAACErWe+WqvdWbl68PxepY5WObxjvN64YbimjB+qJnEx+sM7S3XqE//VrOQtKigsKnP5+YVFevDDFbp5xkL1aFFfs28ZRYlDlcA1cgAAAAhLa1Mz9doPG3XFkDbq16ZhmfOamUZ1aaKRnRM0Z/VOPfnFGt351mL9a8463XpaF53bt6UiDyuCOzMCtxaYv3Gvxh3XXn88p4dqRXEcBFUDp1YCAAAg7DjnNPaVRC3bmqE5d56kxnVrHfHzP1ueqn9+uUardmSqa7N6+v1pXXVmr+aKiDAlbkjTTdMXan9ugR65pI8u6N8qRFsC/K9gT63kiBwAAADCzifLduiHdWl68IJeR1zipMARurN6N9cZPZvp42Xb9dQXa/SbaQvUs0V9jeySoFe+/1ntGtfRtAnD1K15XAi2ADg2FDkAAACEley8Aj300Qr1aFFfY4a2PaZlRUSYzu3bUmf3bqEPFm/V01+u1YvfbtCZvZrp8Uv7MSolqiyKHAAAAMLKv+as17Z9OXp69ABFHcHIk2WJjDBdNKC1zuvbUiu2Z6hPqwYyK3nwFKAqoMgBAAAgbGzcvV8vfrtBFw1opSHtG1f48qMiI9S3ddkDpwBVAcPuAAAAIGw8+NEKRUea/nB2d7+jAL6iyAEAACAsfLUyVV+v2qnbTuuqpvVj/Y4D+CqkRc7MGprZLDNbZWYrzWxEKNcHAACA6iknv1APfrRCnZvW07jj2/sdB/BdqK+Re1rSp865X5tZLUl1Qrw+AAAAVEMvf7dBKWnZmjp+mKIraIATIJyFrMiZWX1JJ0gaJ0nOuTxJeaFaHwAAAKqnrekH9NycdTq7d3ON7JLgdxygSgjlnzM6Stol6TUzW2hmL5tZ3cNnMrPrzSzJzJJ27doVwjgAAAAIRw/PXiFJ+tOvevicBKg6QlnkoiQNlPSCc26ApP2S7j18Jufci865wc65wU2aNAlhHAAAAISb79fu1sdLd+imkzqrdSOu0gEOCmWR2yJpi3Mu0ft+lgLFDgAAAChXXkGR7vtgmdo2rqOJJ3T0Ow5QpYSsyDnndkjabGbdvIdOlbQiVOsDAABA9fL6jxu1ftd+3XdeT8VGR/odB6hSQj1q5c2SpnkjVm6QdG2I1wcAAIBqYGdGjv755Rqd0r2pTu3RzO84QJUT0iLnnFskaXAo1wEAAIDq5++frFJ+odNfz+3pdxSgSuImHAAAAKhS5m/co3cXbtX1J3RU+4RfDHoOQBQ5AAAAVCGFRU5/fX+5WjaI1W9P7uR3HKDKosgBAACgypiemKKV2zP0p1/1VJ1aoR7OAQhfFDkAAABUCWlZuXrss9U6rlO8zunT3O84QJVGkQMAAECV8Pjnq5WdV6gHzu8lM/M7DlClUeQAAADgu8Wb0zVz/maNO669ujSL8zsOUOVR5AAAAOCr9Ow83fP2EsXXjdGtp3XxOw4QFriCFAAAAL7ZmZmjq16ep59379d/rh6kuNhovyMBYYEiBwAAAF9sTT+gsS8nase+HL06bohGdknwOxIQNihyAAAAqHQ/796vK1+aq8zcAk2dMFSD2jX2OxIQVihyAAAAqFSrdmRo7MvzVOScZkwcrt6tGvgdCQg7FDkAAABUmkWb03XNq/NUOzpSUycMU+emjFAJHA2KHAAAACrF3A1pGj9pvhrXq6XpE4arTeM6fkcCwhZFDgAAACE3Z/VO3TglWW0a19HU8cPUvEGs35GAsEaRAwAAQEh9vHS7bp25UF2bxWnydUMVXy/G70hA2KPIAQAAIGRmJW/R3bMWa2DbRnpl3BA1qM194oCKQJEDAABASLz+40bd98FyjeycoBevHqQ6tfjVE6go/GsCAABAhXt+zjo99tlqnd6zmZ4dPUCx0ZF+RwKqFYocAAAAKoxzTo9+tlovfLNeF/Rvqccv7afoyAi/YwHVDkUOAAAAFaKoyOn+D5dr8k8pGjOsrR66oLciIszvWEC1RJEDAADAMSsoLNI9by/V2wu2aOKoDvrjOT1kRokDQoUiBwAAgGOSV1CkW2cu1CfLduj3p3XVLad2psQBIUaRAwAAwFFbtzNLD3y4XN+t3a0//6qHJozq6HckoEagyAEAAOAzNRuSAAAgAElEQVSI5BcW6YsVqZryU4p+2pCmWpEReuTiPrpiaFu/owE1BkUOAAAAQdm+74BmzNusmfM2aWdmrlo1rK27zuymy4e0UUK9GL/jATUKRQ4AAAClKipy+mH9bk2dm6IvV+5UkXM6qWsT/X14O53UrakiGZUS8AVFDgAAAL+Qnp2nWclbNC1xk37evV+N69bSxFEddeWwtmrTuI7f8YAajyIHAACAQxZvTteUuSn6cPE25RYUaVC7Rrr11C46u09zxURF+h0PgIciBwAAUMMdyCvUh4u3acrcFC3duk91akXqkkGtNXZYO/VsWd/veABKQJEDAACooXZm5Ojf/92gWcmblZFToK7N6unBC3rpogGtFBcb7Xc8AGWgyAEAANRAny7brnvfWar9uQU6s1dzXTW8nYZ2aMyNvIEwQZEDAACoQbJyC/TAB8v1VvIW9WnVQE9d3l+dm9bzOxaAI0SRAwAAqCGSU/bo928s1pa92frdyZ11y6ldVCsqwu9YAI4CRQ4AAKCayy8s0jNfrdXzc9apVaPaevOGERrcvrHfsQAcA4ocAABANbZ+V5Z+/8YiLdmyT78e1Fr3ndeTgUyAaoAiBwAAUA055zQ1cZMenr1CsdGReuHKgTq7Twu/YwGoIBQ5AACAamZXZq7ueXuJvl61U6O6JOjxS/upWf1Yv2MBqEAUOQAAgGrkixWpuvftJcrMLdB95/XUNSPaKyKCWwoA1Q1FDgAAoBrYn1ugh2av0Ix5m9WzRX3NuKK/ujaL8zsWgBChyAEAAIS5BZv26vY3FillT7ZuPLGTfn96F8VERfodC0AIUeQAAADCVEFhkZ6bs07Pfr1OzevHasbE4RreMd7vWAAqAUUOAAAgzDjntHxbhv783jIt2pyuiwa00gMX9FJ9bisA1BgUOQAAgDCQlpWr79ft1ndrd+u7tbuUmpGr+rFRemb0AJ3fr6Xf8QBUMoocAABAFZRXUKTklL36bu0ufbt2l5ZtzZAkNagdrZFdEnRClwSd2qOZEurF+JwUgB8ocgAAAFWAc04bdu/Xd2t26du1uzV3Q5qy8woVFWEa2LaR7ji9q0Z1baI+rRooktsJADUeRQ4AAMAn+7Lz9cP63fp2zS59t3a3tqYfkCS1j6+jSwa21qguCRrRKV5xXPsG4DAUOQAAgErknNPL3/2s2Uu3a8mWdBU5KS4mSsd1jtdvTuqkE7o0Udv4On7HBFDFUeQAAAAq0fNz1unxz9eoX+sG+t0pXXRi1wT1a91QUZERfkcDEEYocgAAAJXkq5WpeuKLNbqwf0s9dXl/mXGtG4Cjw59+AAAAKsG6nZm6deYi9W7ZQI9c0pcSB+CYUOQAAABCbN+BfE2cnKzY6Aj956pBio2O9DsSgDDHqZUAAAAhVFjkdOvMhdq8J1vTJw5Xy4a1/Y4EoBqgyAEAAITQ45+v1jerd+mhC3traIfGfscBUE1waiUAAECIfLh4m174Zr1GD22rscPb+R0HQDVCkQMAAAiB5dv26a5ZizW4XSM9cH4vv+MAqGYocgAAABUsLStX109OVqM6tfTC2EGqFcWvXAAqFtfIAQAAVKD8wiLdNH2Bdmfl6q0bR6hJXIzfkQBUQxQ5AACACvTw7JWau2GPnrq8n/q2buh3HADVFMf5AQAAKsib8zdr0o8bNWFkB100oLXfcQBUYxQ5AACACrBg0179+b1lGtUlQfee3d3vOACqOYocAADAMUrNyNGNU5LVvEGsnh09QFGR/IoFILT4KQMAAHAMcvILdcOUZGXlFuilqwerYZ1afkcCUAMw2AkAAMBRcs7pL+8t06LN6fr32EHq1jzO70gAagiOyAEAAByl13/cqLeSt+iWU7vorN7N/Y4DoAahyAEAAByFH9fv1t9mr9TpPZvptlO7+B0HQA1DkQMAADhCm/dk66ZpC9Qhoa6evKyfIiLM70gAahiKHAAAwBHIzivQxMlJKixyeunqwYqLjfY7EoAaiMFOAAAAguSc011vLdGa1Ey9du1QdUio63ckADUUR+QAAACC9NzX6zR76Xbdc1Z3ndi1id9xANRgFDkAAIAgfLx0u574Yo0uGtBK15/Q0e84AGo4ihwAAEA5lmxJ1+1vLtKgdo30yCV9ZMbgJgD8RZEDAAAow459OZo4OUnxdWP0n6sGKSYq0u9IAECRAwAAKM2BvEJNmDxfWTkFemXcYCXUi/E7EgBIYtRKAACAEhUVOd3+5iIt35ahV64ZrO7N6/sdCQAO4YgcAABACZ76co0+WbZDfzqnh07p3szvOADwPyhyAAAAh3lv4VY9+/U6XTGkjcaP7OB3HAD4BYocAABAMckpe3X320s0vGNjPXhBb0aoBFAlUeQAAAA8W/Zm64YpSWrZIFYvXDlItaL4VQlA1RTSwU7MbKOkTEmFkgqcc4NDuT4AAICjlZVboAmvJym3oEgzrx+iRnVr+R0JAEpVGaNWnuyc210J6wEAADgqhUVOt85YqLU7szTp2iHq3LSe35EAoEycLwAAAGq8f3y6Sl+t2qn7z+upUV2a+B0HAMoV6iLnJH1uZslmdn1JM5jZ9WaWZGZJu3btCnEcAACA//Xm/M168dsNumZEO101or3fcQAgKKEucsc75wZKOlvSTWZ2wuEzOOdedM4Nds4NbtKEv4ABAIDKM3dDmv703lKN6pKgv5zb0+84ABC0kBY559w27/NOSe9KGhrK9QEAAAQrJW2/bpyarLaN6+i5MQMVFckVJwDCR8h+YplZXTOLO/i1pDMkLQvV+gAAAIKVkZOv6ybNlyS9cs0QNagd7XMiADgyoRy1spmkd72baEZJmu6c+zSE6wMAAChXQWGRbpq2QJv2ZGvK+GFqn1DX70gAcMRCVuSccxsk9QvV8gEAAI7GQ7NX6ru1u/WPS/poeMd4v+MAwFHhZHAAAFBjTJmbokk/btTEUR10+ZC2fscBgKNGkQMAADXCVytTdf8Hy3Vq96a69+wefscBgGMSymvkAAAAfJdbUKgnPl+jF7/doF4t6+vp0QMUGWF+xwKAY1JmkTOzWEnnSholqaWkAwqMPDnbObc89PEAAACO3rqdmbplxiKt2J6hq4a30x/P6aHatSL9jgUAx6zUImdm90s6T9I3khIl7ZQUK6mrpEe8kneHc25J6GMCAAAEzzmnqYmb9NBHK1QvJkqvXDNYp/Zo5ncsAKgwZR2Rm++cu7+UaU+aWVNJXCUMAACqlN1Zubpn1hJ9tWqnTuzaRI9d2ldN42L9jgUAFarUIuecm334Y2YWIamecy7DObdTgaN0AAAAVcI3q3fqzreWKCMnX/ef11PXHNde3j1tAaBaKXfUSjObbmb1zayupBWSVpvZXaGPBgAAEJyc/ELd/8FyjXttvhLq1dKHvxupccd3oMQBqLaCGbWyp3Muw8yulPSxpHskJUt6LKTJAAAAgrBqR4ZunbFIq1Mzdd3xHXT3Wd0UG82AJgCqt2CKXLSZRUu6UNJzzrl8M3MhzgUAAFCmoiKnST9u1COfrlKD2tF6/bqhOrFrE79jAUClCKbI/UfSRkmLJX1rZu0kZYQyFAAAQFl2ZuTozllL9O2aXTqtRzP945I+iq8X43csAKg05RY559wzkp45+L2ZbZJ0cihDAQAAlOaLFam65+0lys4r0EMX9taVw9pyLRyAGqes+8iNlTTdOVdU/HHnnJNUYGadJLVwzn0f4owAAAA6kFeoh2av0LTETerZor6eGd1fnZvG+R0LAHxR1hG5eEkLzSxZgcFNdilwQ/DOkk6UtFvSvSFPCAAAaqzCIqe0rFyt3Zmlv76/TOt37dcNJ3TU7Wd0VUwUA5oAqLnKuo/c02b2nKRTJB0vqa+kA5JWSrrKObepciICAIDqKDuvQDv25WhHRo5SM3K0Y1+u9/n/P7YzM1eFRYEx1prVj9G0CcN0fOcEn5MDgP/KvEbOOVco6QvvAwAA4IjkFRTp/UVblZKWXaywBYpaZk7BL+aPi4lSswaxal4/Vp06Jah5gxg1rx+rZvVjNaxjvBrUjvZhKwCg6glm1EoAAIAjtmd/nn4zNVmJP+9RhElN42LVrEGsOjapq+M6xR8qbM3rxx76um4Mv5oAQDD4aQkAACrcmtRMjX99vlIzcvXkZf10Qf9WioxgZEkAqCgUOQAAUKG+XpWqW2YsUu1akXrj+uEa0LaR35EAoNqJKG8GM2tmZq+Y2Sfe9z3NbHzoowEAgHDinNOL367X+NeT1C6+jt6/6XhKHACESLlFTtIkSZ9Jaul9v0bSbaEKBAAAwk9uQaHumrVE//fxKp3du7neunGEWjas7XcsAKi2gilyCc65NyUVSZJzrkBSYUhTAQCAsLE7K1djXkrUrOQtuvXULnpu9EDVqcXVGwAQSsH8lN1vZvGSnCSZ2XBJ+0KaCgAAhIWV2zM04fUk7c7K1XNjBujcvi3LfxIA4JgFU+Rul/SBpE5m9oOkJpJ+HdJUAACgyvts+Q79/o1FiouN0ls3jlDf1g39jgQANUa5Rc45t8DMTpTUTZJJWu2cyw95MgAAUCU55/Svb9brsc9Wq1/rBnrx6sFqVj/W71gAUKOUW+TMLFLSOZLae/OfYWZyzj0Z4mwAAKCKyckv1L1vL9F7i7bp/H4t9eiv+yo2OtLvWABQ4wRzauWHknIkLZU34AkAAKh5dmbkaOKUZC3enK67zuym357USWbc5BsA/BBMkWvtnOsb8iQAAKDKWrZ1nyZOTlJ6dr7+PXaQzurd3O9IAFCjBXP7gU/M7IyQJwEAAFXSx0u369f//lEmadZvRlDiAKAKCOaI3FxJ75pZhKR8BQY8cc65+iFNBgAAfOWc0zNfrdNTX67RwLYN9Z+rBqtJXIzfsQAACq7IPSFphKSlzjkX4jwAAKAKyCso0t2zFuu9Rdt08cBW+vvFfRQTxaAmAFBVBFPk1kpaRokDAKBm2J9boBunJuu7tbt15xldddPJnRnUBACqmGCK3HZJ35jZJ5JyDz7I7QcAAKh+dmfl6rpJ87V8W4YevaSvLhvSxu9IAIASBFPkfvY+ankfAACgGtq8J1tXvZKo7fty9J+xg3Raz2Z+RwIAlKLcIuece6AyggAAAP8s37ZP416br7yCIk2fOEyD2jX2OxIAoAylFjkz+6dz7jYz+1DSL66Pc86dH9JkAACgUvy4frdumJyserFRmn7jCHVpFud3JABAOco6IjfF+/x4ZQQBAACVb/aS7fr9G4vULr6OJo8fqhYNavsdCQAQhFKLnHMu2fuyv3Pu6eLTzOxWSf8NZTAAABBak3/aqPs+WK5BbRvp5WsGq2EdLoUHgHAREcQ815Tw2LgKzgEAACqJc05PfL5af31/uU7t3kxTJwyjxAFAmCnrGrnRksZI6mBmHxSbFCcpLdTBAABAxSsoLNKf31ummfM364ohbfTQhb0VFRnM33UBAFVJWdfI/ajAPeQSJD1R7PFMSUtCGQoAAFS8A3mFunnGQn25MlU3n9JZt5/elRt9A0CYKusauRRJKZJGVF4cAAAQCunZeZrwepKSN+3Vgxf00tUj2vsdCQBwDIK5ITgAAAhj29IP6JpX5yklLVvPjR6oX/Vt4XckAMAxosgBAFCNrU3N1NWvzlNWToEmXTdEx3VK8DsSAKACUOQAAKimklP26LpJSaoVFaGZNwxXr5YN/I4EAKgg5RY5Mzte0v2S2nnzmyTnnOsY2mgAAOBoFBQW6aMl23XvO0vUokFtTb5uqNo0ruN3LABABQrmiNwrkn4vKVlSYWjjAACAo5WakaOZ8zZr5vxN2r4vR/1aN9Cr44Yovl6M39EAABUsmCK3zzn3SciTAACAI1ZU5PTD+t2aNneTvliZqsIip1FdEnTfeb10Wo+m3CMOAKqpYIrcHDN7TNI7knIPPuicWxCyVAAAoEx79udpVvJmTU/cpI1p2Wpct5YmjOqgMUPbql18Xb/jAQBCLJgiN8z7PLjYY07SKRUfBwAAlMY5p+SUvZqWuEmzl25XXkGRhrRvpN+f3lVn9W6umKhIvyMCACpJuUXOOXdyZQQBAAAly8zJ13sLt2pa4iat2pGpuJgojR7SRmOGtVO35nF+xwMA+CCYUSsbSLpP0gneQ/+V9KBzbl8ogwEAUNMt27pP0xJT9P6ibcrOK1TvVvX1yMV9dF6/lqobwx2EAKAmC+Z/gVclLZN0mff9VZJek3RxqEIBAFBTFRU5vbdoq17/KUWLN6crNjpC5/drqSuHtVO/Ng39jgcAqCKCKXKdnHOXFPv+ATNbFKpAAADUVGtTM3XP20u0YFO6Ojetp/vO66mLB7ZWg9rRfkcDAFQxwRS5A2Y20jn3vXToBuEHQhsLAICaI6+gSC98s17Pz1mnOjGRevKyfrpoQCuZmd/RAABVVDBF7jeSXveulTNJeySNC2UoAABqigWb9uret5doTWqWzu/XUn89r6cSuIE3AKAcwYxauUhSPzOr732fEfJUAABUc/tzC/TYZ6v1+k8b1aJ+rF4dN1indG/mdywAQJgotciZ2Vjn3FQzu/2wxyVJzrknQ5wNAIBq6ZvVO/Wnd5dp274Dunp4O911VnfVYxRKAMARKOt/jbreZ25QAwBABdizP09/+2iF3l24VZ2b1tOsG0doULvGfscCAIShUoucc+4/3ucHKi8OAADVj3NOHyzepgc+XKHMnHzdcmoX3XRyJ8VERfodDQAQpoK5Ifijkh5SYKTKTyX1k3Sbc25qiLMBAFBpklP2auGmverRor56tqivRnVrVchyt6Yf0J/fXao5q3epf5uG+sclfdWtOSe7AACOTTAn5J/hnLvbzC6StEXSpZLmSKLIAQCqha3pB3Tta/OUkVNw6LGWDWLVs2Wg1AU+N1DrRrUVERHcLQEKi5ymzk3Ro5+ukpN033k9dfWI9ooM8vkAAJQlmCJ38C6k50ia4Zzbw31tAADVRUFhkW6buVCFRU7v33S8MnMKtGL7Pq3YlqEV2zP09aqdKnKBeeNiogJH7IoVvC7N6v3iFMniN/Y+oWsTPXxhb7VpXMeHrQMAVFfBFLkPzWyVAqdW/tbMmkjKCW0sAAAqx7Nfr9P8jXv1z8v7q1+bhpKkkV0SDk3PyS/UmtTMQ8VuxbYMvZW0WfvzCiVJURGmzk3rHSp26dn5+s+361UvJkpPXd5PF/bnxt4AgIpnzrnyZzJrJCnDOVdoZnUk1XfO7ajoMIMHD3ZJSUkVvVgAAEqUuCFNo1+aqwsHtNKTl/UP+nlFRU6b9mQfKnYHP+/ICPyd84L+LfXXc3sqnht7AwCOkJklO+cGlzdfMIOdXCrpU6/E/VnSQAUGP6nwIgcAQGVJz87TbW8sUrv4unrwgt5H9NyICFP7hLpqn1BX5/RpcejxtKxc7TuQr45N6lV0XAAA/kdEEPP8xTmXaWYjJZ0p6XVJL4Q2FgAAoeOc0z1vL9HurFw9c8WACrsZd3y9GEocAKBSBFPkCr3Pv5L0gnPufUkVMyYzAAA+mJq4SZ8tT9U9Z3VXn9YN/I4DAMARC6bIbTWz/0i6TNLHZhYT5PMAAKhyVu3I0N8+WqETuzbRdcd38DsOAABHJZhCdpmkzySd5ZxLl9RY0l0hTQUAQAgcyCvULTMWqn5stB6/tF/Q94QDAKCqKbfIOeeyJe2UNNJ7qEDS2lCGAgAgFB6avUJrUrP01OX91CSOESUBAOGr3CJnZvdJukfSH7yHoiVNDWUoAAAq2qfLtmta4ibdcGJHjerSxO84AAAck2BOrbxI0vmS9kuSc26bpLhQhgIAoCJtTT+gu2ctUb/WDXTH6d38jgMAwDELpsjlucBdw50kmVnd0EYCAKDiFBQW6baZC1XkpGdGD1CtKMbrAgCEv2D+N3vTG7WyoZlNlPSlpJdCGwsAgIrx7NfrNH/jXj18UW+1i+dvkQCA6qHcO6A65x43s9MlZUjqJumvzrkvQp4MAIBjlLghTc9+vVaXDGytC/q38jsOAAAVpswiZ2aRkj5zzp0mifIGAAgb6dl5uu2NRWoXX1cPXNDL7zgAAFSoMk+tdM4VSso2swaVlAcAgGPmnNPds5Zod1aunrligOrFlHsCCgAAYSWY/9lyJC01sy/kjVwpSc65W4JZgXdUL0nSVufcuUeVEgCAIzA1cZM+X5GqP/+qh/q05m+RAIDqJ5giN9v7OFq3Slopqf4xLAMAgKCs2pGhv320Qid1a6Lrju/gdxwAAEIimMFOXjezWpK6K3ALgtXOubxgFm5mrSX9StLDkm4/lqAAAJTnQF6hbpmxUPVjo/X4pf0UEWF+RwIAICTKvf2AmZ0jab2kZyQ9J2mdmZ0d5PL/KeluSUVlLP96M0sys6Rdu3YFuVgAAH7podkrtCY1S09d3k8J9WL8jgMAQMgEcx+5JyWd7Jw7yTl3oqSTJT1V3pPM7FxJO51zyWXN55x70Tk32Dk3uEmTJkGFBgDgcJ8u265piZt0w4kdNaoL/58AAKq3YIrcTufcumLfb5C0M4jnHS/pfDPbKGmmpFPMbOqRRwQAoGxb0w/o7llL1K9NQ915Rje/4wAAEHLBDHay3Mw+lvSmAtfIXSppvpldLEnOuXdKepJz7g+S/iBJZnaSpDudc2MrIjQAAAdl5uTr5ukLVOSkZ67or+jIYP5GCQBAeAumyMVKSpV0ovf9LkmNJZ2nQLErscgBABBq2/cd0LWvzde6nVl6dvQAtYuv63ckAAAqRTCjVl57rCtxzn0j6ZtjXQ4AAAet3J6ha1+br6zcAr127RCuiwMA1CjlFjkz6yDpZknti8/vnDs/dLEAACjdt2t26bfTFqheTJTeunGEerTgVqUAgJolmFMr35P0iqQPVcZtBAAAqAxvzt+sP7y7VF2bxem1cUPUvEGs35EAAKh0wRS5HOfcMyFPAgBAGZxzeuLzNXpuzjqd0LWJnh8zQHGx0X7HAgDAF8EUuafN7D5Jn0vKPfigc25ByFIBAFBMbkGh7pm1RO8t2qYrhrTR3y7szeiUAIAaLZgi10fSVZJO0f8/tdJ53wMAEFL7svN1w9Qkzd2wR3ed2U2/PamTzMzvWAAA+CqYIneRpI7OubxQhwEAoLjNe7J17aT52pSWraev6K8L+rfyOxIAAFVCMEVusaSGknaGOAsAAIcs2ZKu6yYlKa+gUJPHD9XwjvF+RwIAoMoIpsg1k7TKzObrf6+R4/YDAICQ+HJFqm6esfD/tXfncVWViR/Hvw87CIIobggKuO8ruWeNlamN7WZNuWb7ZOvUNC3TTFNN/abF9kUtK23RVkvLNDMtVxR3xQ0RRVFBVETgPr8/uDrkuKByOffC5/16+YJ77rnnfK/e14GvzznPUc3wIE0efZ4a145wOhIAAF6lLEXucY+nAADA7f1ft+iJr1apdWyk3h3aRTERwU5HAgDA65y2yFlr5xhj6kjq4l600FrLaZYAgHLlclk9/d0avT13s/q2qKOXh7RXWFBZ/r8RAICq57RzNxtjrpW0UNI1kq6VtMAYc7WngwEAqo7DhcW6c9JSvT13s4Z1b6Q3b+xEiQMA4BTK8lPyEUldjo7CGWNiJM2U9JkngwEAqoY9Bwp08/uLlbItR38b0EIjeyZwewEAAE6jLEXO77hTKfeoDCN5AACcTmZOvq5/+zftyD2s167vqEvb1HM6EgAAPqEsRW66MWaGpEnux4Mlfee5SACAquBAQZFGTFikPQeO6KObu6pTwxpORwIAwGeUZbKTB4wxV0rqKclIesta+7nHkwEAKq2iYpfu+mipNuw6oPHDulDiAAA4QyctcsaYxpLqWGvnWWunSprqXt7bGJNkrd1YUSEBAJXLP6et0ex1u/XUFa3Vu2mM03EAAPA5p7rW7UVJeSdYfsj9HAAAZ2zCvM2aMH+LRvVM0A3nNXQ6DgAAPulURa6RtTb1+IXW2sWSGnksEQCg0pq1NktPfrNaF7Wso4f7t3A6DgAAPutURS7kFM+FlncQAEDltjpzv+76KEUt6lXXS9e1l78ftxgAAOBsnarILTLG3Hz8QmPMSElLPBcJAFDZZO0/rJHvLVJESKDeHdqFm30DAHCOTvWTdIykz40xN+i/xa2zpCBJV3g6GACgcjh0pEij3lus3PxCfXprN9WNPNUJHwAAoCxOWuSstVmSuhtjLpDU2r14mrV2VoUkAwD4PJfLaszkZVqVmau3b+qsVvUjnY4EAEClUJb7yM2WNLsCsgAAKplnpq/V96uz9PhlLfWHFnWcjgMAQKVxqmvkAAA4ax8tSNdbP2/STd0aalj3Rk7HAQCgUqHIAQDK3S8bsvXolyvVp1mMHhvYUsYwQyUAAOWJIgcAKFcbsvJ024dL1KR2uMYO6aAAf37UAABQ3vjpCgAoN9kHCjR8wiIFB/jr3WFdFBES6HQkAAAqJYocAKBcHC4s1s3vL1b2gQK9O7SzYqNCnY4EAEClxR1ZAQDnzOWyuv/T5UpJz9Ebf+qodnFRTkcCAKBSY0QOAHDOXpi5Xt+k7tBDlzZXv9b1nI4DAEClR5EDAJyTz5ZkaOysNF3XJU639E50Og4AAFUCRQ4AcNZ+27RHD09NVfekmvrH5a25zQAAABWEIgcAOCtpu/J0y8Qlio8O0+s3dFIgtxkAAKDC8FMXAHBGrLWavDBdf3xlngL8jMYPS1ZkGLcZAACgIjFrJQCgzHbnFejhqamauWaXuifV1PPXtFN9bjMAAECFo8gBAMrkh9VZemhKqvIKivTowJYa3r2R/Py4Jg4AACdQ5AAAp3SgoEj/+Hq1Pl68TS3rVdek69qraZ0Ip2MBAFClUeQAACe1ZOte3fPxcm3bd0i39UnSPX2bKiiAy6sBAHAaRQ4A8D+OFLn00o/r9fpPG1U/KlSf3NJNXRpFOx0LAAC4UeQAAL+TtitPYz5eppXb9+vazg306MCWighhVkoAALwJRQ4AIElyuaze+zP07GIAACAASURBVHWLnvluraoFB+iNP3VSv9Z1nY4FAABOgCIHABVgQ1aeXpmdpuXbcvTMVW3VNbGm05F+Z0duvh74NFW/pGXrwua19cxVbVQ7IsTpWAAA4CQocgDgQasz9+uV2Rv03cqdCg30V42wIN3wzgI90r+FhvdoJGOcn77/6+WZeuTzFSostnrqita6PjneK3IBAICTo8gBgAesyMjVy7M26IfVWQoPDtDtfZI0smeiAvyN7v14uZ78ZrVSM3L09JVtFRrk70jG3EOFeuyrlfpyWabax0XphcHtlVCrmiNZAADAmaHIAUA5WrJ1n8bO2qCf1u1W9ZAAjenbRMO7Jygy7L+Thbx1Yye9MjtNL8xcr/VZB/TmjZ0UFx1WoTl/2ZCtBz5brl15Bbr3oqa6vU+SAvy5rQAAAL7CWGudznBM586d7eLFi52OAQBnbMGmPRo7K02/pGWrRligRvVK1E3dGp5ytsfZa3fpz5NT5GeMxg7poN5NYzyeM2PfIf3r2zX6dsVOJcZU0wvXtle7uCiP7xcAAJSNMWaJtbbzadejyAHA2bHWav7GPXrpxw1auHmvaoUHa3TvBN1wXkNVCy7bCQ9bsg/qlolLtH5Xnu6/uJlu75PkkevT8o8U6405G/XGnI0yRrq9T2ON7p2okEBnTusEAAAnVtYix6mVAHCGrLX6af1ujf1xg5am56hO9WA9fllLDUmOP+Ni1KhWNX1+R3c9+FmqnpuxTisycvX8te0UXsYiWJas363cqaemrdH2nHwNbFtPD/dvodio0HLZPgAAcAZFDgDKyFqrmWt2aeysDUrNyFVsVKj+cXlrXdOpwTmNbIUFBWjskA5q1yBKT3+3Rpe/WnLdXFJM+DnlXbtzv/7+1Wr9ummPmteN0OTRXb3utgcAAODscGolAJxCsctqfVaelmzdpw8XpGvNjv2Kjw7THRck6YoODRQUUL4ThMxPy9adk1JUWOTSfwa310Ut65zxNnIOHdELP6zXBwvSFRESoPsubqYhXeKYzAQAAB/ANXIAcBb2HjyiZdv2aenWHC1N36fl23J08EixJCkxppru6NNYg9rX92gp2p6Tr1snLtGK7bn684WNNaZvU/n5nf66uWKX1eRF6Xp+xjrl5hfqhvMa6t6LmqpGtSCPZQUAAOWLa+QA4DSKil1al5Wnpek5Stm6TynbcrQ5+6Akyd/PqEW9CF3ZsYE6NoxSx/gaio8Oq5AbZcdGherTW7vpb1+s1Muz0rRie65eHNzhd7cwON6iLXv1+JertHrHfiUnROuJy1qpZf3qHs8KAACcwYgcgCoj+0CBUtJLRtpS0vcpNSNXh9yjbbXCg9QhvoY6xtdQh/gotW0QqbAgZ/+vy1qrDxak68mvV6l+VKjevLGTmtf9fTnbkZuvp79dq6+WZ6p+ZIj+OqCFBrSpVyGFEwAAlD9OrQQASQVFxfrXtDWavW630vcekiQF+Bm1rF/9WGnrGF9DDWqEem35WbJ1r279YKkOHC7Sv69uq8va1dfhwmK9M3eTXp29UcXW6tbeibq1T5Lj5RMAAJwbihyAKs/lsrprcoqmpe7QRS3rqHPDGurYsIZa149UaJBv3T9t1/7Duv3DpVq8dZ+u7tRACzbv0ba9+erXqq4eGdBCcdFhTkcEAADlgGvkAFRp1lo9+c1qTUvdoYcvba5bzk9yOtI5qV09RB/d3FX/nLZa7/+6VU1qh+uDkeepZ5NaTkcDAAAOoMgBqJRen7NRE+Zv0cieCRrdO9HpOOUiKMBPTw5qrRu7NlSjWtUUyO0EAACosihyACqdTxdv07+nr9Mf29XXI/1beO21b2erSZ0IpyMAAACH8d+5ACqVWWuz9NDUFerZuJaev6Zdme6/BgAA4GsocgAqjaXp+3T7h0vVol6E3rixk4ICOMQBAIDKid9yAFQKabsOaMSERapTPUTjhyUrPJgzxwEAQOVFkQPg83bmHtbQcQsV4Gf0/ohkxUQEOx0JAADAoyhyAHxabn6hho5bqJxDRzRheLIa1qzmdCQAAACP49wjAD7rcGGxbn5/sTZlH9D4YclqHRvpdCQAAIAKQZED4JOKXVZjJi/Tws179fKQDtwYGwAAVCmcWgnA51hr9diXKzV91U49OrCl/tiuvtORAAAAKhRFDoDPefnHNH24IF23nJ+okT0TnI4DAABQ4ShyAHzKRwvS9cLM9bqyY6we6tfc6TgAAACOoMgB8Bnfr9qpv32xQn2axejZq9rKGON0JAAAAEdQ5AD4hMVb9uquSSlq0yBKr93QUYH+HL4AAEDVxW9CALze+qw8jZiwSLFRoRo/rIvCgphwFwAAVG0UOQBeLTMnX0PHLVRIoL/eG5Gs6GpBTkcCAABwHEUOgNfae/CIbhq3UAcOF+m9EcmKiw5zOhIAAIBX4PwkAF5p295DumncQmXm5GvC8GS1qFfd6UgAAABegyIHwOus3J6rYeMXqbDYpQ9HnafOjaKdjgQAAOBVKHIAvMrcDbt168QligoL0uTR56lx7QinIwEAAHgdihwAr/FFynbd/+lyNa4drvdGJKtO9RCnIwEAAHglihwAx1lr9dbPm/T0d2vVLbGm3rypk6qHBDodCwAAwGt5rMgZY0Ik/Swp2L2fz6y1j3tqfwB8k8tl9Y9pqzV+3hYNbFtP/3dtOwUH+DsdCwAAwKt5ckSuQNKF1toDxphASb8YY76z1v7mwX0C8CGHC4t136fLNS11h0b2TNAj/VvIz884HQsAAMDreazIWWutpAPuh4HuP9ZT+wNQPoqKXRr06jz5GaPRvRN1aeu6CvAv/1tO5uYXavT7i7Vg81490r+Fbu6dWO77AAAAqKw8eo2cMcZf0hJJjSW9aq1dcIJ1RksaLUnx8fGejAOgDL5clqlVmftVp3qw7pqUorjoUN3cK1HXdIpTaFD5nPK4M/ewho1fqI27D+il69prUPvYctkuAABAVWFKBs48vBNjoiR9Lukua+3Kk63XuXNnu3jxYo/nAXBixS6ri/4zR8GB/vrmrp6auSZLb8zZqJT0HEVXC9LQbo10U7eGqlEt6Kz3sSErT0PHLdT+w0V688ZO6tG4Vjm+AwAAAN9mjFlire18uvUqZNZKa22OMeYnSf0knbTIAXDWN6mZ2pR9UK/f0FH+fkaXtKqri1vW0aIt+/TmnI16YeZ6vTFnowZ3idPIngmKiw47o+0v2rJXo95brKAAP318S1e1qh/poXcCAABQuXly1soYSYXuEhcqqa+kZz21PwDnxuWyenV2mprWCdclreoeW26MUXJCtJITorU+K09v/bxJHy7Yqom/bdWANvV0y/mJZSpk01fu1N2TUxRbI1TvDU8+4xIIAACA//LkiFw9Se+5r5Pzk/SJtfYbD+4PwDmYsWqn1meVXLN2spkjm9aJ0PPXtNN9FzfV+Hlb9NGCdH21PFO9mtTSrecnqXtSTRnzv6+d+OsWPfbVKrWPi9K7Q7so+hxOzQQAAEAFXSNXVlwjBzjDWqv+L/+igsJi/XDv+fIv4y0AcvML9dGCdI2bt1m78wrUOra6bumddGymS2utnv9+nV6dvVF9W9TW2CEdy23CFAAAgMrIq66RA+DdZq7ZpTU79uv/rmlX5hInSZGhgbqtT5KG92ikL1K2662fN/1upsvUjFx9tiRDQ5Lj9I9BrT1yGwMAAICqiCIHVHHWWo2dtUHx0WEa1L7+WW0jJNBf1yXH69rOcfrBPdPlY1+ukiSN6dtEd/+hyQlPuQQAAMDZocgBVdyc9buVmpGrZ65sc84jZn6lZrpcsnWf8g4X6YLmtcspKQAAAI6iyAFVmLVWL/+4QbFRobqyY4Ny264xRp0bRZfb9gAAAPB7XLACVGHzN+7R0vQc3donSUEBHA4AAAB8Bb+5AVXYyz9uUJ3qwbqmU/mNxgEAAMDzKHJAFbVg0x4t2LxXt56fpJBAbgkAAADgSyhyQBU1dlaaaoUHa0hyvNNRAAAAcIYockAVtDR9n35Jy9bo3gmMxgEAAPggihxQBY39cYNqhAXqhvMaOh0FAAAAZ4EiB1QxKzJyNXvdbo3qlahqwdyBBAAAwBdR5IAq5uVZGxQZGqibujEaBwAA4KsockAVsmbHfv2wOkvDezRSREig03EAAABwlihyQBXyyqw0hQcHaHj3BKejAAAA4BxQ5IAqYkNWnr5duUPDujdSZBijcQAAAL6MIgdUEa/MTlNooL9G9GQ0DgAAwNdR5IAqYHP2QX29PFM3dm2o6GpBTscBAADAOaLIAVXAq7PTFBTgp1G9Ep2OAgAAgHJAkQMqufQ9h/R5ynZdn9xQMRHBTscBAABAOaDIAZXc63PS5O9ndMv5jMYBAABUFhQ5oBLbnpOvz5ZkaHDnONWpHuJ0HAAAAJQTihxQib05Z6Mk6dY+SQ4nAQAAQHmiyAGVVNb+w5q8aJuu7tRAsVGhTscBAABAOaLIAZXUm3M2qdhlddv5jZ2OAgAAgHJGkQMqoewDBfpo4VZd3j5W8TXDnI4DAACAckaRAyqht+du0pEil+64gGvjAAAAKiOKHFDJ7D14RBN/3arL2tVXYky403EAAADgARQ5oJIZ98tm5RcW684LuDYOAACgsgpwOgCAc7f34BGt2J6rFRk5em/+FvVvXU9N6kQ4HQsAAAAeQpEDfExufqFWbs9VakauVmzPUWpGrjL25R97vnndCN13cVMHEwIAAMDTKHKAFztQUKRV23O14lhxy9Xm7IPHno+PDlO7uCjd2LWh2jaIUqvY6qoeEuhgYgAAAFQEihzgJVwuq5RtOVqRkaPU7blakZGrtN0HZG3J8/UjQ9SmQaSu7tRAbWIj1SY2UjWqBTkbGgAAAI6gyAFe4EiRS3d+tFTfr86SJNUKD1a7BpEa0Lae2jWIUuvYSMVEBDucEgAAAN6CIgc4rLDYpbsmlZS4By5ppqs6NlCd6sEyxjgdDQAAAF6KIgc4qLC4ZCRuxqosPXFZSw3rkeB0JAAAAPgA7iMHOKSw2KU/T0rRjFVZepwSBwAAgDNAkQMcUFjs0t2TU/Tdyp16bGBLDafEAQAA4AxQ5IAKVljs0pjJy/Ttip3624AWGtGTEgcAAIAzQ5EDKlBRsUtjPl6maSt26G8DWmhUr0SnIwEAAMAHUeSACnKsxKXu0CP9KXEAAAA4exQ5oAIUFbt0zyfL9U3qDv21f3Pd3JsSBwAAgLNHkcMZcbms7p6cov/7fp0KioqdjuMTiopduveT5fp6eaYeurS5RvdOcjoSAAAAfBz3kcMZmb1ul75clilJmr5yp56/pp3axUU5nMp7Fbus7vt0ub5anqm/9GuuW8+nxAEAAODcMSKHM/LWz5tUPzJE79zUWQcKinTFa/P0zHdrdbiQ0bnjFbus7vtkmb5clqkH+zXTbX0ocQAAACgfFDmU2YqMXC3YvFfDeySob8s6mnFPb13bOU5vzNmoAS/PVUr6Pqcjeo1il9UDny7XF8sy9cAlzXR7n8ZORwIAAEAlQpFDmb09d5MiggN0XXKcJKl6SKCeuaqt3huRrPwjxbrq9fl6+ts1VX50rthl9cBnyzU1Zbvuv7ip7riAEgcAAIDyRZFDmWzPyde0FTt0XXKcIkICf/fc+U1jNOOe3hrcJV5v/rxJ/V+eqyVbq+boXLHL6sHPUjV16Xbdd1FT3XlhE6cjAQAAoBKiyKFMxv+yWZI0rEfCCZ+PCAnU01e20Qcjz1NBoUtXvzFfT01bXaVG51wuq4empGrK0gzd07ep7voDJQ4AAACeQZHDae0/XKjJi7ZpYNt6io0KPeW6PZvU0ox7euv65Hi9PXez+r80V4u37K2gpM5xuaz+MiVVny7J0Ji+TXR3X0ocAAAAPIfbD+C0Ji9M14GCIt3cq2w3sQ4PDtBTV7TRgDb19OCUVF3z5q8a3j1BD1zSTKFB/h5Oe2astfpqeaa2ZB9SkculIpdVscuqsNilYpdVkcuqqNjl/mrdy1wqKra/Wzc3v1Brd+bp7j800Zi+TZ1+WwAAAKjkKHI4pcJil8bP26KuidFqHRt5Rq/t3riWZozprWenr9W4eZs1a22W/n11OyUnRHso7Zn7buVO3T15mSTJGCnQz0/+fkYBfkYB/kb+fn7Hvg/wM/L3Mwr0L71OyffR1YL06MCWGtGjkbNvCAAAAFUCRQ6n9O2KHdqRe1j/vLz1Wb2+WnCAnhzUWpe2rqcHpyzX4Ld+1dBujfRgv2YKC3L243e4sFj/+naNmteN0Fd39lRQAGcaAwAAwDfwmytOylqrt37epKSYarqgWe1z2la3pJqaMaa3hnZrpAnzt6jfi85fO/fO3E3K2Jevxwa2pMQBAADAp/DbK07q1017tCpzv0b1SpSfnznn7YUFBeiJP7bSx6O7yhhp2PhF2pGbXw5Jz9zO3MN6dfZG9WtVV90b13IkAwAAAHC2KHI4qXfmblbNakG6okNsuW73vMSamjjiPBW7rB79YqWsteW6/bJ4dvpaFVurv/ZvUeH7BgAAAM4VRQ4nlLYrT7PW7tJN3RopJLD8Z5qMrxmm+y5uqplrdumb1B3lvv1TWbJ1nz5P2a5RPRMUXzOsQvcNAAAAlAeKHE7onbmbFRzgpz91jffYPob3SFC7BpF64qtV2nfwiMf2U5rLZfXk16tUOyJYt1/QuEL2CQAAAJQ3ihz+x+68Ak1N2a6rOjVQzfBgj+3H38/omavaKje/UP+Yttpj+yltasp2Lc/I1V/6NVd4MJO2AgAAwDdR5PA/Jv62VYXFLo3smeDxfbWoV1239UnS1KXbNWf9bo/u60BBkf49fa3axUWV+3V/AAAAQEWiyOF38o8Ua+KvW/SH5nWUFBNeIfu888LGSoqppr9OXaGDBUUe289rs9O0K69Aj1/Wslxm4QQAAACcQpHD70xZmqF9hwp1cy/Pj8YdFRzgr2evaqvM3Hw9//06j+wjfc8hvTN3s67sEKuO8TU8sg8AAACgolDkcIzLZfXuL5vVtkGkkhOiK3TfnRtF68auDTVh/hYtTd9X7tt/6tvV8vczerBf83LfNgAAAFDRKHI4ZuaaLG3OPqibeyXKmIo/9fDBfs1Vr3qIHpqSqiNFrnLb7ry0bM1YlaU7LkhS3ciQctsuAAAA4BSKHI55Z+5mxUaF6tLWdR3Zf3hwgJ66oo3WZx3Qaz+llcs2i4pdevLr1WpQI1SjeiWWyzYBAAAAp1HkIElati1HC7fs1fAejRTg79zH4oLmtTWofX29OjtN67Pyznl7kxama11Wnh7p38IjNzYHAAAAnECRgyTp7bmbFBESoOuSPXcD8LJ6bGBLhQcH6C9TUlXssme9nZxDR/SfH9ara2K0+jk0yggAAAB4AkUO2rb3kL5bsUPXJ8d7xU2ya4YH6/HLWiklPUfv/7rlrLfz4swNys0v1GMDWzlyzR8AAADgKRQ5aPy8LfIzRsN6NHI6yjGD2tdXn2Yxem7GOmXsO3TGr9+QlaeJv23VkOR4taxf3QMJAQAAAOdQ5Kq43PxCfbwoXZe1q696kaFOxznGGKOnrmgjI+mvn6+UtWU/xdJaqye/Wa2wIH/de1FTz4UEAAAAHEKRq+ImLUzXwSPFGlWBNwAvq9ioUD3Yr7l+Xr9bn6dsL/PrflyzS3M3ZGtM36aqGR7swYQAAACAMyhyVdiRIpcmzNui7kk11ap+pNNxTujGrg3VqWENPfnNamUfKDjt+gVFxfrntNVKiqmmm7o1rICEAAAAQMWjyFVh01Zkauf+w7rZi++v5udn9MyVbXSooFh//3r1adefMG+Ltuw5pEcHtlSgg7dRAAAAADyJ33SrKGut3vp5s5rUDtf5TWOcjnNKTepE6I4LGuvr5Zn6cU3WSdfbnVegsbPSdGHz2urTrHYFJgQAAAAqFkWuipq/cY/W7NivUb0S5Ofn/VPz39YnSc3qROhvX6xU3uHCE67z/Ix1OlxYrL8NaFHB6QAAAICKRZGrot6eu0m1woM0qH2s01HKJCjAT89c1UY79x/Ws9PX/s/zKzJy9cmSbRrWvZESY8IdSAgAAABUHIpcFbQ+K08/rdutod0aKSTQ3+k4ZdYhvoaGd0/QB7+la+HmvceWW2v1969XKTosSHf9oYmDCQEAAICKQZGrgt6Zu0khgX76U1ffm9Xx/kuaqkGNUD00JVWHC4slSV+n7tDirft0/yXNFBka6HBCAAAAwPMoclXMrrzD+iIlU1d3aqAa1YKcjnPGwoIC9K8r2mhT9kGNnbVB+UeK9fS3a9SyXnVd2znO6XgAAABAhQjw1IaNMXGS3pdUV5JL0lvW2pc8tT+Uzfvzt6rQ5dLInt57y4HT6d00Rld1bKA352xS+t587cg9rBcHt5e/D0zaAgAAAJQHT47IFUm6z1rbQlJXSXcYY1p6cH84jYMFRfpgwVZd1KKOEmpVczrOOXl0YAtFhQXq6+WZGtC2ns5LrOl0JAAAAKDCeKzIWWt3WGuXur/Pk7RGkm9MkVgJ5R4q1NBxC5WbX6hbzk9yOs45iwoL0jNXtlXzuhF6+NLmTscBAAAAKpTHTq0szRjTSFIHSQtO8NxoSaMlKT4+viLiVDlZ+w/rpncXalP2Ab0ypKM6NazhdKRy0bdlHfVtWcfpGAAAAECF8/hkJ8aYcElTJI2x1u4//nlr7VvW2s7W2s4xMTGejlPlbM4+qKten69t+w5p/LBkDWhbz+lIAAAAAM6RR0fkjDGBKilxH1prp3pyX/hfK7fnaui4hbKSJt3cVe3iopyOBAAAAKAceHLWSiPpXUlrrLX/8dR+cGLzN2Zr9PtLFBkaqPdHJispJtzpSAAAAADKiSdPrewh6UZJFxpjlrn/9Pfg/uA2feUODRu3SPUiQzTltu6UOAAAAKCS8diInLX2F0nc2KuCTVqYrkc+X6H2cVEaN6yLosJ876bfAAAAAE6tQmathOdZa/XaTxv13Ix16tMsRq/d0FFhQfzzAgAAAJURv+lXAi6X1T+mrdb4eVt0efv6eu6adgr09/iEpAAAAAAcQpHzcYXFLj3w6XJ9sSxTw3s00qMDWsrPjzNaAQAAgMqMIufDDh0p0u0fLtVP63brgUua6fY+SSqZLBQAAABAZUaR81E5h45oxIRFWrYtR09f2UZDkuOdjgQAAACgglDkfNCO3Hzd9O5Cbd1zSK/d0FH9WtdzOhIAAACACkSR8zEbdx/QTe8uVG5+oSaM6KLuSbWcjgQAAACgglHkfEhqRo6GjV8kPyNNHt1VrWMjnY4EAAAAwAEUOR/gcll9nZqpv05doRrVgjRx5HlKqFXN6VgAAAAAHEKR82LWWv28IVv/nr5WqzL3q01spN4Z2ll1qoc4HQ0AAACAgyhyXiolfZ+enb5Wv23aq7joUL04uL0ua1df/twjDgAAAKjyKHJeZkNWnp7/fp1mrMpSrfAg/f2PrTQkOV5BAX5ORwMAAADgJShyXmJ7Tr5e/GG9pizNUFhQgO67qKlG9ExQtWD+iQAAAAD8Hi3BYXsPHtGrs9M08detkpFG9kzQbX0aK7pakNPRAAAAAHgpipxDDhYU6d1fNuutnzfp0JEiXd2pgcb0bar6UaFORwMAAADg5ShyFaygqFiTFqRr7Kw07Tl4RP1a1dX9lzRV49oRTkcDAAAA4CMochWk2GX15bLt+s8P65WxL1/dEmvqwX7N1CG+htPRAAAAAPgYilwFmJ+WrSe/Wa21O/PUOra6/nVFG/VqUkvGcCsBAAAAAGeOIudhy7blaNj4RaofFaJXru+g/q3ryY97wQEAAAA4BxQ5D9qdV6BbJy5R7erB+vz2HqrBTJQAAAAAygFFzkMKi12646Olysk/oim3dafEAQAAACg3FDkP+de3a7Rw8169dF17taof6XQcAAAAAJWIn9MBKqPPUzI0ft4WjeiRoEHtY52OAwAAAKCSociVs5Xbc/XQlBXqmhith/s3dzoOAAAAgEqIIleO9h48olsmLlF0tSC9cn1HBfrz1wsAAACg/HGNXDkpKnbprklLtftAgT69pZtqhQc7HQkAAABAJcWQUTl5bsY6zUvbo39e3lrt4qKcjgMAAACgEqPIlYNvUjP15s+b9Keu8bq2c5zTcQAAAABUchS5c7R253498GmqOjWsoccGtnI6DgAAAIAqgCJ3DnIPFeqWiUsUERKg12/oqKAA/joBAAAAeB6TnZylYpfV3R+nKDMnX5NHd1Xt6iFORwIAAABQRTCEdJZenLleP63brccva6VODaOdjgMAAACgCqHInYUZq3Zq7Kw0De4cpxvOi3c6DgAAAIAqhiJ3htJ25em+T5arXYNI/X1QKxljnI4EAAAAoIqhyJ2BvMOFGj1xiYID/PT6nzopJNDf6UgAAAAAqiAmOykjl8vq3k+Wa+ueQ/pw1HmqHxXqdCQAAAAAVRQjcmX0yuw0/bA6S4/0b6GuiTWdjgMAAACgCqPIlcGstVl6YeZ6XdEhVsN7NHI6DgAAAIAqjiJ3GpuzD+ruycvUom51/euKNkxuAgAAAMBxFLlTOFhQpFsmLpa/n9GbN3ZSaBCTmwAAAABwHkXuFHbuP6zDhS69MqSj4qLDnI4DAAAAAJKYtfKUkmLCNfPe8xUUQN8FAAAA4D1oKKdBiQMAAADgbWgpAAAAAOBjKHIAAAAA4GMocgAAAADgYyhyAAAAAOBjKHIAAAAA4GMocgAAAADgYyhyAAAAAOBjKHIAAAAA4GMocgAAAADgYyhyAAAAAOBjKHIAAAAA4GMocgAAAADgYyhyAAAAAOBjKHIAAAAA4GMocgAAAADgYyhyAAAAAOBjKHIAAAAA4GMocgAAAADgYyhyAAAAAOBjKHIAAAAA4GMocgAAAADgYyhyAAAAAOBjjLXW6QzHGGN2S9rqdA5UmFqSsp0OAZwBPrPwNXxm4Wv4zMLXeOIz29BaG3O6lbyqyKFqMcYsUEMUPAAACQNJREFUttZ2djoHUFZ8ZuFr+MzC1/CZha9x8jPLqZUAAAAA4GMocgAAAADgYyhycNJbTgcAzhCfWfgaPrPwNXxm4Wsc+8xyjRwAAAAA+BhG5AAAAADAx1DkAAAAAMDHUORQIYwxccaY2caYNcaYVcaYu93Lo40xPxhjNri/1nA6K3CUMcbfGJNijPnG/TjBGLPA/Xn92BgT5HRG4ChjTJQx5jNjzFr3sbYbx1h4M2PMPe7fCVYaYyYZY0I4zsLbGGPGGWN2GWNWllp2wmOrKfGyMSbNGJNqjOnoyWwUOVSUIkn3WWtbSOoq6Q5jTEtJD0n60VrbRNKP7seAt7hb0ppSj5+V9IL787pP0khHUgEn9pKk6dba5pLaqeSzyzEWXskYEyvpz5I6W2tbS/KXdJ04zsL7TJDU77hlJzu2XiqpifvPaEmvezIYRQ4Vwlq7w1q71P19nkp+wYiVNEjSe+7V3pN0uTMJgd8zxjSQNEDSO+7HRtKFkj5zr8LnFV7DGFNdUm9J70qStfaItTZHHGPh3QIkhRpjAiSFSdohjrPwMtbanyXtPW7xyY6tgyS9b0v8JinKGFPPU9kocqhwxphGkjpIWiCpjrV2h1RS9iTVdi4Z8DsvSnpQksv9uKakHGttkftxhkr+MwLwBomSdksa7z4d+B1jTDVxjIWXstZul/S8pHSVFLhcSUvEcRa+4WTH1lhJ20qt59HPMEUOFcoYEy5piqQx1tr9TucBTsQYM1DSLmvtktKLT7Aq92+BtwiQ1FHS69baDpIOitMo4cXc1xQNkpQgqb6kaio5Le14HGfhSyr0dwWKHCqMMSZQJSXuQ2vtVPfirKNDzu6vu5zKB5TSQ9IfjTFbJE1Wyak+L6rkFIkA9zoNJGU6Ew/4HxmSMqy1C9yPP1NJseMYC2/VV9Jma+1ua22hpKmSuovjLHzDyY6tGZLiSq3n0c8wRQ4Vwn190buS1lhr/1Pqqa8kDXV/P1TSlxWdDTietfZha20Da20jlVx8P8tae4Ok2ZKudq/G5xVew1q7U9I2Y0wz96I/SFotjrHwXumSuhpjwty/Ixz9zHKchS842bH1K0k3uWev7Cop9+gpmJ5grGXEGp5njOkpaa6kFfrvNUd/Vcl1cp9IilfJQf0aa+3xF5QCjjHG9JF0v7V2oDEmUSUjdNGSUiT9yVpb4GQ+4ChjTHuVTM4TJGmTpOEq+Q9bjrHwSsaYv0sarJKZrVMkjVLJ9UQcZ+E1jDGTJPWRVEtSlqTHJX2hExxb3f8p8YpKZrk8JGm4tXaxx7JR5AAAAADAt3BqJQAAAAD4GIocAAAAAPgYihwAAAAA+BiKHAAAAAD4GIocAAAAAPgYihwA4JSMMQfOYN0+xpju57CvKGPM7ad4/hFjzCpjTKoxZpkx5ryz3Vd5MMY0MsasdH/f2RjzskM55juxXwCAcwKcDgAAqFT6SDog6WyLRZSk2yW9dvwTxphukgZK6mitLTDG1FLJPdO8gvteQR67X9Bp9n3W5RkA4JsYkQMAnDFjzGXGmAXGmBRjzExjTB1jTCNJt0q6xz1a1ssYE2OMmWKMWeT+08P9+ieMMeOMMT8ZYzYZY/7s3vQzkpLcr3/uuN3Wk5R99ObA1tpsa22me3tbjDHPGmMWuv80PllO9/JwY8x4Y8wK9+jeVe7lFxtjfjXGLDXGfGqMCT/Be+9kjFlujPlV0h2llvcxxnxT6v29Z4z53p3tSmPMv937m26MCSy1rTnGmCXGmBnGmHru5T+Vej/rjTG93MtbuZctc+du4l5+wP3VGGOeM8asdO9rcKlsPxljPjPGrDXGfOi+cS0AwEdR5AAAZ+MXSV2ttR0kTZb0oLV2i6Q3JL1grW1vrZ0r6SX34y6SrpL0TqltNJd0iaRkSY+7y81Dkja6X//Acfv8XlKcu9i8Zow5/7jn91trkyW9IunFk+V0L39UUq61to21tq2kWe4Rvr9J6mut7aiS0bV7T/Dex0v6s7W222n+jpIkDZA0SNIHkmZba9tIypc0wP1+x0q62lrbSdI4SU+Ven2A+/2MkfS4e9mtkl6y1raX1FlSxnH7vFJSe0ntJPWV9NzRciipg3tbLSUlSupxmvwAAC/GqZUAgLPRQNLH7pIQJGnzSdbrK6llqcGf6saYCPf309yjawXGmF2S6pxqh9baA8aYTpJ6SbrAvf+HrLUT3KtMKvX1hdPk7CvpulLb3meMGaiSkjPPnTdI0q+lMxhjIiVFWWvnuBdNlHTpSSJ/Z60tNMaskOQvabp7+QpJjSQ1k9Ra0g/u/flL2lHq9VPdX5e415c7zyPGmAaSplprNxy3z56SJllriyVlGWPmSOoiab+khdbaDPf7WObe5i8nyQ4A8HIUOQDA2Rgr6T/W2q+MMX0kPXGS9fwkdbPW5pde6C4uBaUWFasMP5PcBeUnST+5C9JQSROOPl161dPkNMetf3TZD9baIaeIcKLXnczRU0BdxphCa+3R17lU8l6NpFWnGNk7+vdz7O/GWvuRMWaBSkb6ZhhjRllrZx2X75R5jt8mAMA3cWolAOBsREra7v5+aKnleZIiSj3+XtKdRx8YY9qfZrvHv/4YY0yzo9eEubWXtLXU48Glvh4dSTtZzuNz1ZD0m6Qepa6vCzPGNC2dwVqbIynXGNPTveiG07yfU1knKcY9iYuMMYHGmFaneoExJlHSJmvty5K+ktT2uFV+ljTYGONvjImR1FvSwnPICADwUhQ5AMDphBljMkr9uVclI1ufGmPmSsoute7Xkq5wT8bRS9KfJXV2T8yxWiXXeJ2UtXaPSk5tXHmCyU7CJb1njFltjElVyWmQT5R6Ptg9WnW3pHvcy06W85+Sarj3s1zSBdba3ZKGSZrk3v5vKrmO73jDJb3qnuwk/wTPl4m19oikqyU9686wTNLpZp8cLGml+9TI5pLeP+75zyWlSlouaZZKrl3cebYZAQDey/z3TA8AAHyTMWaLpM7W2uzTrQsAQGXAiBwAAAAA+BhG5AAAAADAxzAiBwAAAAA+hiIHAAAAAD6GIgcAAAAAPoYiBwAAAAA+hiIHAAAAAD7m/wHMO8zExzL72wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "\n",
    "plt.plot(latent_list, file[0])\n",
    "plt.title('1st Plot - compression time vs latent space dimension')\n",
    "plt.xlabel('Latent Space dimension')\n",
    "plt.ylabel('Compression time (s)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see for larger latent space dimension, compression time increases.\n",
    "\n",
    "\n",
    "Then, First hidden layer effects on classification accuracy\n",
    "So, we setup a different test, this time for second hidden layer of the encoder section of the deep autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 4s 45ms/step - loss: 0.0612 - acc: 0.0000e+00 - val_loss: 0.0607 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 317us/step - loss: 0.0604 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0595 - acc: 0.0000e+00 - val_loss: 0.0588 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.0577 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0575 - acc: 0.0000e+00 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0564 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0552 - acc: 0.0000e+00 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0540 - acc: 0.0000e+00 - val_loss: 0.0529 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0527 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0513 - acc: 0.0000e+00 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0498 - acc: 0.0000e+00 - val_loss: 0.0484 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0483 - acc: 0.0000e+00 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.0454 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0453 - acc: 0.0000e+00 - val_loss: 0.0440 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0439 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0425 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0411 - acc: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 263us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 242us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 252us/step - loss: 0.0240 - acc: 0.0105 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0217 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 231us/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 252us/step - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 242us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 210us/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 221us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
      "Train on 95 samples, validate on 32 samples\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 5s 48ms/step - loss: 0.0664 - acc: 0.0105 - val_loss: 0.0654 - val_acc: 0.0312\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0655 - acc: 0.0105 - val_loss: 0.0645 - val_acc: 0.0312\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0646 - acc: 0.0105 - val_loss: 0.0634 - val_acc: 0.0312\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0636 - acc: 0.0105 - val_loss: 0.0623 - val_acc: 0.0312\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0625 - acc: 0.0105 - val_loss: 0.0611 - val_acc: 0.0312\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0612 - acc: 0.0105 - val_loss: 0.0598 - val_acc: 0.0312\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0599 - acc: 0.0105 - val_loss: 0.0584 - val_acc: 0.0312\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0585 - acc: 0.0105 - val_loss: 0.0569 - val_acc: 0.0312\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0570 - acc: 0.0105 - val_loss: 0.0552 - val_acc: 0.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0553 - acc: 0.0105 - val_loss: 0.0535 - val_acc: 0.0312\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0536 - acc: 0.0105 - val_loss: 0.0518 - val_acc: 0.0312\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0519 - acc: 0.0105 - val_loss: 0.0503 - val_acc: 0.0312\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0502 - acc: 0.0105 - val_loss: 0.0488 - val_acc: 0.0312\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0488 - acc: 0.0105 - val_loss: 0.0474 - val_acc: 0.0312\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0473 - acc: 0.0105 - val_loss: 0.0461 - val_acc: 0.0312\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0459 - acc: 0.0105 - val_loss: 0.0447 - val_acc: 0.0312\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0446 - acc: 0.0105 - val_loss: 0.0434 - val_acc: 0.0312\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0432 - acc: 0.0105 - val_loss: 0.0422 - val_acc: 0.0312\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0420 - acc: 0.0105 - val_loss: 0.0412 - val_acc: 0.0312\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0410 - acc: 0.0105 - val_loss: 0.0402 - val_acc: 0.0312\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0400 - acc: 0.0105 - val_loss: 0.0393 - val_acc: 0.0312\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0390 - acc: 0.0105 - val_loss: 0.0384 - val_acc: 0.0312\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0382 - acc: 0.0105 - val_loss: 0.0376 - val_acc: 0.0312\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0373 - acc: 0.0105 - val_loss: 0.0369 - val_acc: 0.0312\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 165us/step - loss: 0.0366 - acc: 0.0105 - val_loss: 0.0362 - val_acc: 0.0312\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 329us/step - loss: 0.0359 - acc: 0.0105 - val_loss: 0.0355 - val_acc: 0.0312\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 165us/step - loss: 0.0352 - acc: 0.0105 - val_loss: 0.0348 - val_acc: 0.0312\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 197us/step - loss: 0.0345 - acc: 0.0105 - val_loss: 0.0342 - val_acc: 0.0312\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0338 - acc: 0.0105 - val_loss: 0.0335 - val_acc: 0.0312\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 192us/step - loss: 0.0332 - acc: 0.0105 - val_loss: 0.0329 - val_acc: 0.0312\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0326 - acc: 0.0105 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 200us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 179us/step - loss: 0.0313 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 24us/step - loss: 0.0307 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 325us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 189us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 107us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0252 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 329us/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0232 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 164us/step - loss: 0.0227 - acc: 0.0000e+00 - val_loss: 0.0226 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#   This method cleans the remnant files from the last run\n",
    "clean()\n",
    "\n",
    "#   Here, we define the parameters and values to investiate\n",
    "encoder_i_list = range(10,50,25)\n",
    "test_params = [{'encoder_i':encoder_i_list}]\n",
    "\n",
    "#   Perform sensitivity analysis\n",
    "file = test(test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd plot - classification accuracy vs 1st hidden layer dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(encoder_i_list, file[3])\n",
    "plt.title('2nd Plot - classification accuracy vs 1st hidden layer dimension')\n",
    "plt.xlabel('First hidden layer dimension')\n",
    "plt.ylabel('Classification Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As it can be seen in the above figure, accuracy increase when 1st hidden layer dimension of the encoder section increases. \n",
    "\n",
    "More analysis can be done using the same code to investigate effects of other model parameters on the accuracy or runtime of autoencoder or classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
